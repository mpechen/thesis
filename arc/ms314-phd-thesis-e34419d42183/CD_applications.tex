%to do:
%KDD cycle from CD perspective - the focus is on continuous, evaluation, monitoring, and handling/update, i.e. the arrows. Automation vs expert involvement offline and online
%- Do the state-of-the-art change handling mechanisms cover all the demands of current day industry?
%- What domain driven elements are needed for change handling in evolving time-series data?
%- Are widely used evaluation methods equally fair for all domains of (time-series) prediction under the influence of changes?

\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{graphicx}
\usepackage{amsmath,graphicx}
\usepackage{tabularx,multirow,rotating} %for tables
\usepackage{url}
\usepackage{caption}
\usepackage{rotating}
\usepackage{amssymb}
\usepackage{color}
\usepackage{slashbox}
\usepackage{array}
\usepackage{ragged2e}
\usepackage{pgfplots}
\usepackage{enumerate}
\newcolumntype{P}[1]{>{\RaggedRight\hspace{0pt}}p{#1}}

\begin{filecontents}{boiler.dat}
sk boil
100 10978
101 10975
102 10872
103 10995
104 10864
105 10767
106 10874
107 10768
108 10842
109 10947
110 10801
111 10881
112 10949
113 10796
114 10917
115 10830
116 10726
117 10847
118 10733
119 10775
120 10933
121 10817
122 10867
123 10937
124 10765
125 10866
126 10830
127 10661
128 10822
129 10746
130 10716
131 10870
132 10758
133 10806
134 10913
135 10731
136 10774
137 10778
138 10627
139 10788
140 10755
141 10698
142 10870
143 10753
144 10764
145 10894
146 10755
147 10744
148 10768
149 10587
150 10694
151 10747
152 10658
153 10826
154 10747
155 10697
156 10816
157 10708
158 10685
159 10743
160 10556
161 10621
162 10745
163 10624
164 10796
165 10780
166 10686
167 10811
168 10679
169 10653
170 10739
171 10604
172 10647
173 10758
174 10604
175 10730
176 10748
177 10629
178 10782
179 10684
180 10573
181 10655
182 10510
183 10555
184 10700
185 10555
186 10622
187 10724
188 10580
189 10729
190 10672
191 10538
192 10634
193 10517
194 10521
195 10681
196 10598
197 10629
198 10722
199 10553
200 10665
201 10660
202 10480
203 10596
204 10512
205 10458
206 10614
207 10880
208 10588
209 10707
210 10553
211 10579
212 10620
213 10435
214 10556
215 10538
216 10449
217 10578
218 10529
219 10508
220 10665
221 10556
222 10558
223 10616
224 10407
225 10491
226 10510
227 10401
228 10588
229 10529
230 10461
231 10597
232 10502
233 10501
234 10585
235 10384
236 10446
237 10543
238 10434
239 10600
240 10590
241 10507
242 10632
243 10534
244 10488
245 11506
246 10444
247 10438
248 10542
249 10425
250 10549
251 10564
252 10425
253 10587
254 10517
255 10409
256 10492
257 10359
258 10353
259 10492
260 10358
261 10432
262 10543
263 10393
264 10536
265 10524
266 10391
267 10487
268 10346
269 10289
270 10476
271 10396
272 10417
273 10525
274 10367
275 10476
276 10495
277 10322
278 10423
279 10332
280 10239
281 10432
282 10363
283 10379
284 10510
285 10357
286 10396
287 10461
288 10294
289 10377
290 10536
291 10249
292 10439
293 10381
294 10343
295 10508
296 10423
297 10387
298 10475
299 10283
300 10331
301 10338
302 10202
303 10367
304 10344
305 10268
306 10397
307 10329
308 10318
309 10432
310 10235
311 10230
312 10912
313 10180
314 10338
315 10356
316 10264
317 10397
318 10326
319 10349
320 10431
321 10283
322 10222
323 10305
324 10142
325 10284
326 10340
327 10201
328 10360
329 10329
330 10245
331 10352
332 10201
333 10185
334 10271
335 10107
336 10177
337 10306
338 10155
339 10301
340 10323
341 10204
342 10304
343 10171
344 10087
345 10218
346 10135
347 10171
348 10294
349 10144
350 10258
351 10284
352 10121
353 10243
354 10146
355 10017
356 10159
357 10103
358 10094
359 10272
360 10130
361 10167
362 10266
363 10092
364 10189
365 10149
366 10019
367 10153
368 10111
369 10082
370 10251
371 10149
372 10147
373 10252
374 10064
375 10134
376 10100
377 9961.8
378 10118
379 10095
380 10018
381 10156
382 10104
383 10073
384 10234
385 10067
386 10043
387 10087
388 9917
389 10036
390 10026
391 9989.4
392 10098
393 10036
394 10019
395 10485
396 10537
397 10475
398 10537
399 10374
400 10749
401 11147
402 11075
403 11225
404 11187
405 11112
406 11658
407 11948
408 11882
409 11984
410 11946
411 12506
412 12992
413 12828
414 12955
415 13246
416 13613
417 13872
418 13790
419 13925
420 14350
421 14241
422 14266
423 14450
424 14293
425 14382
426 14457
427 14325
428 14451
429 14389
430 14218
431 14308
432 14247
433 14285
434 14424
435 14284
436 14324
437 14441
438 14310
439 14454
440 14442
441 14266
442 14335
443 14298
444 14251
445 14435
446 14352
447 14329
448 14467
449 14307
450 14352
451 14347
452 14184
453 14285
454 14273
455 14198
456 14368
457 14316
458 14269
459 14438
460 14300
461 14292
462 14358
463 14126
464 14211
465 14285
466 14181
467 14346
468 14323
469 14213
470 14389
471 14312
472 14231
473 14310
474 14097
475 14135
476 14240
477 14152
478 14308
479 14322
480 14186
481 14299
482 14270
483 14174
484 14294
485 14091
486 14073
487 14252
488 14148
489 14242
490 14307
491 14189
492 14316
493 14272
494 14122
495 14278
496 14130
497 14070
498 14268
499 14156
500 14213
501 14296
502 14150
503 14267
504 14272
505 14107
506 14169
507 14067
508 14006
509 14214
510 14699
511 14150
512 14266
513 14119
514 14219
515 14267
516 14098
517 14136
518 14046
519 13961
520 14174
521 14140
522 14103
523 14232
524 14075
525 14141
526 14216
527 14017
528 14066
529 14032
530 13913
531 14084
532 14097
533 14022
534 14191
535 14070
536 14074
537 14182
538 13973
539 14007
540 14027
541 13923
542 14089
543 14076
544 13974
545 14155
546 14106
547 14043
548 14175
549 13978
550 13953
551 14118
552 13889
553 14069
554 14110
555 13971
556 14084
557 14073
558 13999
559 14133
560 13928
561 13875
562 13991
563 13849
564 13986
565 14082
566 13956
567 14069
568 14066
569 13956
570 14088
571 13979
572 13855
573 13979
574 13876
575 13972
576 14110
577 13922
578 14038
579 14048
580 13902
581 14006
582 13924
583 13795
584 13966
585 13913
586 13902
587 14042
588 13874
589 13963
590 14056
591 13925
592 13975
593 13886
594 13746
595 13920
596 13906
597 13859
598 14003
599 13855
600 13900
601 13986
602 13839
603 13883
604 13743
605 13686
606 13818
607 13853
608 13872
609 13942
610 13832
611 13843
612 13978
613 13806
614 13827
615 13837
616 13685
617 13809
618 13788
619 13847
620 13943
621 13778
622 13894
623 13887
624 16780
625 13821
626 13724
627 13658
628 13856
629 13770
630 13777
631 13898
632 13751
633 14069
634 13901
635 13704
636 13764
637 13698
638 13604
639 13807
640 13790
641 13877
642 13883
643 13748
644 13804
645 13898
646 13697
647 13735
648 13718
649 13596
650 13748
651 13757
652 13686
653 13848
654 13729
655 13713
656 13823
657 13634
658 13650
659 13676
660 13537
661 13705
662 13741
663 13641
664 13809
665 13756
666 13702
667 13808
668 13609
669 13600
670 13689
671 13555
672 13703
673 13729
674 13607
675 13747
676 13731
677 13653
678 13790
679 13589
680 13512
681 13627
682 13523
683 13652
684 13748
685 13587
686 13711
687 13750
688 13594
689 13707
690 13589
691 13483
692 13591
693 13499
694 13582
695 13707
696 13547
697 13628
698 13674
699 13538
700 13633
701 13527
702 13416
703 13576
704 13494
705 13516
706 13647
707 13501
708 13589
709 13672
710 13524
711 13581
712 13520
713 13371
714 13568
715 13550
716 13499
717 13627
718 13512
719 13553
720 13687
721 13505
722 13531
723 13487
724 13326
725 13477
726 13474
727 13426
728 13612
729 13481
730 13464
731 13601
732 13449
733 13470
734 13472
735 13294
736 13450
737 13495
738 13414
739 13579
740 13502
741 13460
742 13597
743 13425
\end{filecontents}

\usepackage{epigraph}

\begin{document}
%
\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads

\mainmatter              % start of the contributions

\title{An overview of concept drift applications}
%\title{Reference Framework for Handling Concept Drift: An Application Perspective}
%\title{A survey of application tasks for adaptive learning under concept drift}
%\subtitle{An Application Perspective}



\titlerunning{Concept Drift Applications}  % abbreviated title (for running head)

\author{Indr\.e \v{Z}liobait\.e\inst{1,2} \and Mykola Pechenizkiy\inst{3} \and Jo{\~a}o Gama\inst{4}}

\authorrunning{\v{Z}liobait\.e et al.}

\tocauthor{Indr\.e \v{Z}liobait\.e, Mykola Pechenizkiy and Joao Gama}

\institute{Dept. of Computer Science, Aalto University, Finland\\
\and
Helsinki Institute for Information Technology, Finland
\and
Eindhoven University of Technology, The Netherlands \\
\and
LIAAD, INESC TEC and University of Porto, Portugal \\
\email{indre.zliobaite@aalto.fi, m.pechenizkiy@tue.nl, jgama@fep.up.pt}}


\maketitle


%If we emphasize velocity, some applications won't have a perfect fit any more, like credit loans or antibiotic resistance
\begin{abstract}
%Data streams is a type of so called big data, which has high velocity.
In most challenging data analysis applications, data evolve over time and must be analyzed in near real time.
Patterns and relations in such data often evolve over time, thus, models built for analyzing such data quickly become obsolete over time.
In machine learning and data mining this phenomenon is referred to as concept drift.
The objective is to deploy models that would diagnose themselves and adapt to changing data over time.
%In machine learning and data mining fields, the problem of concept drift has been recognized and actively studied almost for two decades.
%The problem refers to changes in the distribution of the data over time.
%These changes affect the performance of models inferred from historical data, as a result, some models may become no longer relevant.
%The mainstream concept drift research often focuses on improving the prediction accuracy in the crystalized setting
%where data is clean and pre-processed, there are no delays in feedback and only limited types of changes may happen.
%In contrast, in real life applications data often contains noise and redundancy, and feedback may come late and be inaccurate.
This chapter provides an application oriented view towards concept drift research, with a focus on supervised learning tasks.
%with a focus on characterizing supervised learning tasks in an application driven manner.
First we overview and categorize application tasks for which the problem of concept drift is particularly relevant.
Then we construct a reference framework for positioning application tasks within a spectrum of problems related to concept drift.
%Based on this framework we identify the relations between the different groups of methods that handle concept drift and different types of application tasks.
%To facilitate this process we categorize the applications based on the properties of the underlying supervised learning tasks.
Finally, we discuss some promising research directions from the application perspective, and present recommendations for application driven concept drift research and development.
\keywords{evolving data, adaptation, concept drift, data streams}
\end{abstract}

%\setcounter{tocdepth}{4}
%\tableofcontents

\setlength{\epigraphwidth}{0.56\textwidth}
%\renewcommand{\epigraphflush}{center}
\epigraph{\textit{We dedicate this chapter to Dr.~Alexey~Tsymbal who passed away suddenly and unexpectedly in November 2014 at age of 39. Alexey contributed to the progress of data mining and medical informatics on several topics, including notable work on handling concept drift.}}


\section{Introduction}


Realism of the perfect world assumptions in machine learning has been challenged years ago \cite{Hand06}.
One of these challenges relates to an observation that in the real world the data tends to change over time.
As a result, predictions of the models trained in the past may become less accurate as time passes or opportunities to improve the accuracy might be missed.
Thus, learning models need to have mechanisms for continuous diagnostics of performance, and be able to adapt to changes in data over time.

In machine learning, data mining and predictive analytics unexpected changes in underlying data distribution over time are referred to as concept drift \cite{GamaACMCS2014,Tsymbal04,Moreno12,Widmer96}. In pattern recognition the phenomenon is known as covariate shift or dataset shift \cite{Moreno12}. In signal processing the phenomenon is known as non-stationarity \cite{Haykin95}.
Changes in underlying data occur due to changing personal interests, changes in population, adversary activities or they can be attributed to a complex nature of the environment.

The traditional supervised learning assumes that the training and the application data come from the same distribution, as illustrated in Figure~\ref{fig:learning}~(a).
In real life the predictions need to be made online, often in real time.
An online setting brings additional challenges, since it may be expected for the data distribution to change over time.
Thus, at any point in time the testing data may be coming from a different distribution than the training data has come,
as illustrated in Figure~\ref{fig:learning}.
\begin{figure}[h]
\centering
{\footnotesize
\begin{tabular}{cc}
\includegraphics[width=0.3\textwidth]{figures/fig_stationary} &
\includegraphics[width=0.3\textwidth]{figures/fig_stationary_not} \\
(a) stationary & (b) concept drift\\
\end{tabular}
}
\caption{Stationary supervised learning (a) and learning under concept drift (b).}
\label{fig:learning}
\end{figure}

The problem of concept drift is of increasing importance as more and more data is organized in the form of data streams rather than static databases,
and it is unrealistic to expect that data distributions stay stable over a long period of time.
It is not surprising that the problem of concept drift has been studied in several research communities including but not limited to pattern mining, machine learning and data mining, data streams, information retrieval, and recommender systems.
Different approaches for detecting and handling concept drift have been proposed in research literature, and many of them have already proven their potential in a wide range of application domains.
%, e.g. fraud detection, adaptive system control, user modeling, information retrieval, text mining, biomedicine~\cite{DBLP:journals/evs/SebastiaoSRGM13,Koren10,Tsymbal08,DBLP:conf/flairs/LindstromDN10,PechenizkiySIGKDDExpl09,Kadlec11ache}.

%The causes of concept drift are diverse, but all are related with learning over time.
One of the most illustrative cases, is learning against
an adversary (e.g.\ spam filters, intrusion detection). A predictive model aims at
identifying patterns characteristic of the adversary activity, while the
adversary is aware that adaptive learning is used, and tries to change the behavior.
Another context is learning in the presence of hidden variables. User
modelling is one of the most popular learning tasks, where the learning
system constructs a model of the user intentions, which of course are not
observable and may change time to time. Drift also occurs in monitoring
tasks and predictive maintenance. Learning the behaviour of a system(e.g.\
the quality of products in industrial process)  where degradation or
corrosion of mechanical pieces occur over time.

Concept drift is used as a generic term to describe computational problems with changes over time.
These changes may be of countless different types and there are different types of applications that call for different adaptation techniques.
Thus, a solution ``one-size-fits-all" is hardly possible and not desirable for handling concept drift.
On the other hand, real application tasks being seemingly different from each other may share common properties and may have similar needs for adaptation. In order to transfer adaptive techniques from application to application we need to have means to characterize application tasks in a systematic manner.

The main aim and contribution of this chapter is to present tools for describing application tasks with concept drift in a systematic way, to position the existing application driven work using these tools, and define promising directions for future research.
To keep the focus on applications we leave a detailed discussion of concept drift handling methods out of the scope of this paper,
a reader is referred to existing reviews of the methods and techniques \cite{GamaACMCS2014,Tsymbal04,Moreno12,Kadlec11}.
Our study focuses on describing the \emph{research tasks} driven by application needs.
%
%This paper overviews the application areas where the problem of concept drift is relevant.
%The goal is to provide a view to the concept drift research from an application perspective.
%We look for relations between the methods that handle concept drift and application tasks.
%We categorize the applications based on the properties of the underlying supervised learning tasks.
%
%We present a reference framework, which presents a spectrum of problems related to concept drift, that are motivated by real applications.
%We elaborate on a few illustrative examples showing the diversity of application properties that may put constraints on the applicability of some of the generic approaches for handling them.
%%We aim to identify promising future research directions in the field from the application perspective.
%

The chapter is organized as follows.
In Section~\ref{sec:background} we discuss knowledge discovery process in the context of learning from streaming data and handling concept drift.
%In Section~\ref{sec:current} overviews the current evaluation practices of adaptive learning algorithms.
Section \ref{sec:framework} presents a reference framework of concept drift tasks and applications.
This framework is intended to serve as a tool for describing an application oriented task in a systematic way.
%In Section~\ref{sec:properties} describes the main properties of the application tasks with concept drift
%and Section~\ref{sec:landscape} provides a categorization of application areas and tasks based on those properties.
%In relation to these properties %Section~\ref{sec:examples}
%we overview a landscape of application tasks, and in Section \ref{sec:applications}
%we describe the application areas where the problem of concept drift is relevant.
In Section \ref{sec:applications} we survey application oriented published work on adaptive learning, focusing on task formulations, while leaving the techniques out of the scope of this study.
%., and analyze four application examples, that represent different types of tasks.
%We emphasize in what way the settings are different from a typical concept drift handling scenario dominating in the literature.
Section~\ref{sec:conclusion} gives our recommendations towards promising and urgent future research directions from the concept drift application perspective, and concludes the study.

%\section{Background on concept drift handling research}
\section{Knowledge discovery process and industry standards}
\label{sec:background}

In the era of big data, many data mining projects shift their emphasis towards evolving nature of the data that requires to study the automation of feedback loops more thoroughly.
In the standard data mining and machine learning settings the majority of algorithmic techniques have been researched and developed under the assumption of identical and independent data distribution (IID).
In big data applications data arrives in a stream, and patterns in the data are expected to evolve over time, therefore, it is not practical, and often is not feasible to involve a data mining expert to monitor the performance of the models and to retrain the models every time they become outdated. Therefore, interest towards automating development and update of predictive models in the streaming data settings has been increasing.

CRISP-DM model~\cite{crisp} describes the classical data mining process,
where the life cycle of a data mining project spans over six phases:
business understanding, data understanding, data preparation, modeling, evaluation and deployment.
Reinartz's framework~\cite{DBLP:books/sp/Reinartz99} follows CRISP-DM with some modifications, making modeling steps more explicit. The high-level process steps are summarized in Figure~\ref{fig:precrisp}.

Business understanding phase aims at formulating business questions, and translating them into data mining goals.
Data understanding phase aims at analyzing and documenting the available data and knowledge sources in the business according to the formulated goals, and providing initial characterization of data.
Data preparation phase starts from target data selection that is often related to the problem of building and maintaining useful data warehouses.
After selection, the target data is preprocessed in order to reduce the level of noise, pre-process the missing information, reduce data, and remove obviously redundant features.
Next, data exploration phase aims at providing the first insight into the data, evaluate the initial hypotheses, usually, by means
of descriptive statistics and visualization techniques.
Data mining phase covers selection and application of data mining techniques, initialization and further calibration of their parameters to optimal values.
Evaluation phase typically considrs offline evaluation on historical data.
In predictive modeling, one would typically analyze simulated performance of the data mining system with respect to some suitable measures of accuracy (such as precision, recall, or AUC, among others), or utility (for instance, expressed as cost-sensitive classification).
Finally, the most promising predictive model is deployed in operational settings, and the performance is regularly followed up.
\begin{figure}
\centering
\includegraphics[width=\textwidth]{figures/fig_crisp1}
\caption{Knowledge discovery process: from problem understanding to deployment. Arrows indicate the most important and frequent dependencies between the phases.}
\label{fig:precrisp}
\end{figure}

%The arrows in the figure indicate the most important and frequent dependencies between phases. The sequence of the phases is not strict and moving back and forth between different phases normally happens. After a solution has been deployed still some new and possibly more focused business questions can be recognized that will trigger new data analytics processes will be launched.
%Reinartz's framework explicitly shows accumulation of experience achieved during the data mining processes.
%Thus, different feedback loops were considered to be important, but it is not the main stream research.

CRISP-DM model assumes that most of the data mining processes, including data cleaning, feature engineering, algorithm and parameter selection, and final evaluation, performed offline. If anything goes wrong with the deployed model, a data mining expert would analyze the problem, and try to fix it revisiting one or more steps in the process, and retraining the model.

In the streaming settings, it is common to expect changes in data and model applicability. Therefore, monitoring of model performance and model update or relearning becomes a natural and core part of the data mining process.
Figure~\ref{fig:crisp_adm} presents our view towards adaptive data mining process. The main difference with the standard process is that now data preparation, mining, and evaluation steps are automated, there is no manual data exploration, and there is automated monitoring of performance, including change detection and alert services, after deployment.
\begin{figure}
\centering
\includegraphics[width=\textwidth]{figures/fig_crisp22}
\caption{Towards CRISP for Adaptive Data Mining.}
\label{fig:crisp_adm}
\end{figure}

Different strategies for updating learning models have been developed.
Two main strategies can be distinguished. Learning models may evolve continuously, for instance, models can be periodically retrained using a sliding window of a fixed size over the past data (e.g. FLORA1 \cite{Widmer96}). Alternatively, learning models may use trigger mechanisms, to initiate a model update. 
Typically, statistical change detection tests are used as triggers (e.g. \cite{Gama04}). Incoming data is continuously monitored, if changes are suspected, the trigger issues an alert, and adaptive actions are taken. When a change is signalled, the old training data is dropped and the model is updated using the latest data.

Learning systems can use single models or ensembles of models.
Single model algorithms employ only one model for decision making at a time.
Once the model is updated, the old one is permanently discarded.
Ensembles, on the other hand, maintain some memory of different concepts.
The prediction decisions are made either fusing the votes casted by different models or nominating the most suitable model for the time being from the pool of existing models.

Ensembles can be evolving or have trigger mechanisms as well. Evolving ensembles build and validate new models as new data arrives, the rule for model combination is dynamically updated based on the performance (e.g. \cite{Minku10}). Ensembles with triggers proactively assign the most relevant models for decision maxing based on the context (e.g. \cite{Tsymbal08}). 

Table \ref{fig:methods} summarizes the taxonomy of adaptive learning strategies.
\begin{table}[h]
\centering
\caption{Adaptive learning strategies.}
{\footnotesize
\begin{tabular}{|l|cc|}
\hline
	& with triggers & evolving \\ \hline
single model & detectors & forgetting \\
multiple models & contextual & dynamic ensembles\\	
\hline
\end{tabular}
}
\label{fig:methods}
\end{table}

%The simplest forgetting approaches that use a single model employ a \emph{training window of a fixed length}.
%Training window refers to a sequence of instances within a time interval of length $w$, which is shifted in time towards the future when new data arrives.
%At time $t$ the instances that fall into the period from $t-w$ to $t-1$ are used for training.
%At time $t+1$ the instances from $t-w+1$ to $t$ are used and so on.
%The fixed training window is an example of an evolving approach using a single model.
%The window moves forward independently whether a change has actually happened or not.
%Research efforts in adaptive learning with fixed windows focus on determining the window size~\cite{Zliobaite09IDA}.
%More advanced forgetting approach uses \emph{instance weighting}, for example~\cite{Klinkenberg04}.
%
%Basic approaches with trigger mechanisms that use a single model \emph{detect a change point in time} and then discard the old training data that precedes the change point.
%Different methods how to detect a change have been developed, for instance,~\cite{Gama04,Leeuwen08,Nishida07}.
%
%An alternative to using a single model is to use an ensemble of models and achieve adaptivity by manipulating individual model contributions towards the final decision. The evolving ensemble approaches typically monitor
%the errors of individual models. If an individual model predicts correctly,
%its weight towards the final decision is magnified, otherwise the weight is decreased.
%Examples of different evolving adaptive ensembles can be found in~\cite{Kolter06,Bifet09,Minku09}.
%%Some ensembles use triggers, either change detectors \cite{Bifet09b} or
%
%Finally, ensembles may use triggers for nominating the models for the final decision making.
%The incoming data is inspected and described, and the model that that fits the description the closest is selected from the pool of existing models.
%Examples of adapting using ensembles with triggers can be found in \cite{Tsymbal08,Zliobaite09ISMIS,Katakis09,Zliobaite11sligro}.
%
%In addition to presence of triggers and the number of models used, adaptive learning strategies may be characterized as independent from the learning models, or adaptive learning mechanisms may be tailored for particular learning models, e.g.\ for decision trees \cite{Hulten01}.
%
%We enumerated the major strategies and presented a few examples of adaptive learning algorithms.
%Many more algorithms that fall into these categories have been developed in the last decade.
%Since the focus of our study is to survey and categorize concept drift application tasks, a survey of solutions is out of the scope of this study.
%A reader is refereed to overviews \cite{Tsymbal04,Kuncheva08,Zliobaite09,Bifet11moaman,Kadlec11} for more detailed information on the concept drift handling techniques.
%

An important aspect with respect to evaluation of performance of adaptive learning models relates to data collection. An adaptive system collects data, which is biased with respect to adaptations performed. For example, consider a recommender system, where so called ``rich-gets-richer" phenomenon boosts the popularity of already popular items. In such situations relying on learning and evaluation of models on offline data is particularly dangerous, since within-system data does not give an unbiased view towards outside world. Consequently, it is important to develop techniques allowing for online evaluation and online adaptation.

Overall, we are not aware of fully automated and functioning adaptive learning system. It could be that well functioning fragments of such systems already exist in industry, especially in big data (web sized) data analysis, where manual attendance to all the running models is simply infeasible. In academia, except for some isolated cases (e.g.\ \cite{Salvador14}), there has been little attention towards automating data mining process for big data, and we anticipate seeing more of such research efforts in the future.

In the following section we first categorize different big data applications where handling of concept drift is important and then refer to different data mining techniques that are suitable for data preprocessing, predictive modeling and evaluation in the streaming settings.

%We start from an introduction to the problem of concept drift and an overview of the main principles and techniques used for handling concept drift.


%\subsection{Adaptation over time}
%%
%In online setting the learning systems have opportunities to periodically update or retrain themselves using new data
%and this way adapt to concept drift.
%
%Adaptive learning approaches can be \emph{incremental} or use \emph{retraining}, as presented in Figure \ref{fig:adaptivelearning}.
%The incremental approaches incorporate new data into existing models,
%while the retraining approaches discard an old model and build a new one from scratch from the newest data.
%
%The \emph{incremental} learning approaches can be incremental at an instance level, at a batch level or at an ensemble level.
%At an instance level the parameters of the learning model are updated with the information extracted from the latest incoming data point.
%At a batch level the parameters of the model can only be updated after a certain number of incoming data points is accumulated.
%For instance, more than one new data point may be needed for estimating the current accuracy.
%Such an approach is still considered as incremental learning (not retraining), since the old model is not discarded
%to be learned from scratch, but updated in an incremental mode.
%\begin{figure}
%\centering
%\includegraphics[width=0.8\textwidth]{adaptivelearning}
%\caption{Principles of adaptivity in online learning.}
%\label{fig:adaptivelearning}
%\end{figure}
%Incremental learning can also be organized at an ensemble level, where a new model is built with the new data chunk,
%and added to the collection of old models that were built before.
%In such a case individual models are not updated incrementally.
%Adaptivity is achieved by manipulating the weights of individual models to output the final prediction.
%%(How to adapt using computational elements vs. how to adapt computational elements themselves.)

%The s\emph{retraining} approaches retrain a model using selected training data.
%Retraining can be done in full or partially.
%Full retraining means that from a chunk of new data the relevant instances are selected
%and a new learning model is trained from scratch with this new training set.
%Partial retraining means that only some parts of the model are fully replaced.
%Consider the Naive Bayes (NB) classifier as an example.
%NB makes an assumption that the input features are independent from each other.
%Thus, the probability counts for one attribute may be completely replaced while leaving the counts for other attributes in place.
%Such an approach can be beneficial if the drift happens locally and does not affect the whole feature space.
%
%The choice of an adaptive learning approach depends on time and memory imposed by a data stream application, as well as preferences of a designer.
%\textbf{Albert, could you add about time and memory, sublinear processing time, etc.}
%Incremental approaches are typically faster (?).

%the outer circle in the figure denotes the cyclic nature of DM - a DM process continues after a solution has been deployed. If some lessons are learnt during the process, some new and likely more focused business questions can be recognized and subsequently new DM processes will be launched.





%depending on what figure(s) we leave here, we can write the story from different perspectives.
%Concept-drift research, in the context of applications requiring data collection over time and the deployment and evaluation on real data is needed, but also in realistic (close to operational) setting is needed (Fig.~\ref{fig:crisp_adm}).

%move this figure to the discussion or keep here? only one figure?
%\begin{figure}
%\centering
%\includegraphics[width=0.85\textwidth]{crisp_adm}
%\caption{CRISP-Adaptive Data Mining from problem understanding to deployment.}
%\label{fig:crisp_adm}
%\end{figure}
%consider this as paper's contribution too?
%consider also preparing a white paper for CRISP-ADM

%KDD process sketch may look the same. But feedback arrows and application side become more essential.


%How concept drift research {\it covers} the process - some work for data preprocessing, including cleaning and representation space update, but essentially the same preprocessing techniques are used. In supervised learning under concept drift, the same models as under {\it iid} usually are used, but the focus then is either on relearning by feeding the model with the most appropriate instances or on model update mechanisms. Model selection in case of ensembles. The variety of approaches is explain in the following section.
%Model evaluation (and performance monitoring) under concept drift has several peculiarities which we discuss in {\bf Section X}.
%Depending on the operational settings and (predictive modeling) task the focus can be on {\bf incomplete sentence}.



%\subsection{Applicability of the adaptive learning strategies}
%
%\textbf{2 all: please comment / modify the following if you do not agree}
%
%A practitioner may wonder how to chose the appropriate strategy and algorithm for a given application problem.
%
%Roughly but not exhaustively, single models are more suitable and often used when sudden drift is expected.
%That is sensible as a sudden drift instantly and completely replaces the old concept with a new one.
%Therefore, the old model becomes no longer relevant and can be discarded.
%In such cases most of the adaptive algorithm efforts are typically directed towards change detection and replacement of the old model, after that the old models are not preserved.
%
%If gradual or reoccurring drift is expected, ensemble techniques typically prevail.
%Ensemble techniques keep a number of alternative models, which can store past concepts and reuse them if necessary.
%In general, whether implicitly or explicitly, algorithms for handling concept drift are tailored towards the expected change types. %As we Such an approach is not critisized here. By no means it is bad approach.
%%However, we want to emphasize that the application tasks offer and require to take much more properties into consideration.

\section{Categorization of concept drift tasks and applications}
\label{sec:framework}

%We start constructing the framework from organizing properties of the tasks,
%that are related to the problem of concept drift.
We start this section by describing relations between concept drift tasks and applications.
We analyze application tasks in three steps:
\begin{enumerate}[(a)]
\item properties of tasks,
\item landscape of applications,
\item links between tasks and applications.
%\item the map of concept drift application tasks.
\end{enumerate}
%The frame is intended to serve as a tool for describing and positioning a given concept drift application task, as well as positioning the findings related to that given the tasks within the related work.
%The framework is also intended to serve as a tool for identifying promising future research directions in the field of concept drift research.
The following subsections describe each component.
% of the proposed framework.

\subsection{Characterization of application tasks}

%A typical concept drift setting deals with the tabular data (a single relation \textbf{introduce the notions, y=f(x), then describe X,Y,f)}
%that is evolving over time.
%The true labels arrive immediately after the prediction is casted.
%Changes happen suddenly. %What else relevant?

Real application tasks, where concept drift is expected, %may present different variations of these settings and additional, which we discuss in this section. The properties describing the tasks prone to concept drift can be mapped in three dimensions.
can be mapped into three dimensions:
(i) a type of the learning task,
(ii) environment from which data comes,
and (iii) online operational settings.

\subsubsection{Data and task.}
Different types of tasks may be required depending on the intended application (even using the same data source): regression, ranking, classification, novelty detection, clustering, itemset mining.

Prediction makes assertions about the future, or about unknown characteristics of the present. Predictions is probably the most common use of data mining, it covers regression and classification tasks.
Regression is typically considered in demand planning, resource scheduling optimization, user modelling, and, generally, in applications, in which the main objective is to anticipate future behavior of customers. Ranking is a special form of prediction, where partial ordering of alternative choices is required.
Classification is a typical task in diagnosis and decision support, for example, antibiotic resistance prediction, e-mail spam classification, or news categorization.
Ranking is a common task in recommendation, information retrieval, credit scoring and preference learning systems domains.
% in which it is assumed that each item is assigned some relevance score and top scoring items should be selected.
Regression, ranking and classification are supervised learning tasks, where models are trained on examples, where the ground truth is available.

Novelty detection is a common task in fault, fraud detection applications, or identifying abnormal behavior.
Faults in machines, frauds in credit cards transactions, intrusion detection in computer networks, emergent topics in text news, requires some sort of outlier or anomaly detection, which is a basic form of novelty detection.
Novelty detection is a semi-supervised, or unsupervised learning task.
Typically, normal examples are available, but abnormal examples are unknown.
%Note, that by prediction or classification we do not mean regression labels or class labels.
%These are two orthogonal aspects of a learning task.
%Instead, we emphasize that in prediction the labels are about the future events,
%while in classification labels represent something what is already present, but needs to be diagnosed.

Clustering produces a grouping of people or objects, and is a popular task, for instance, in marketing.
Itemset mining aims at finding items that commonly appear together, the task is relevant, for instance, in analyzing shopping baskets in retail.
Patterns may evolve in those groups, new groups may appear or disappear due to changes in the data generating process.
Clustering and itemset mining belong to unsupervised learning tasks, the ground truth is not known.

Orthogonally to different learning tasks, input data may have different forms.
Data can be single or multi-relational, sequential, time series, general graph or particular complex structure, bags of instances or a mix.
Instances can be noisy or highly accurate.
Relational data can be of low or high dimensionality, have a few or lots of missing value, be almost complete or very sparse, have binary, categorical, ordered or numerical attributes.

Moreover, input data can be organized in different ways in terms of its accessibility.
Data can come as a stream of instances or batches, or it can arrive in time-stamped batches.
Data re-access can be allowed, or a single pass over the data may need to be strictly enforced.
There might be randomly or systematically missing values in the incoming data.

\subsubsection{Characteristics of changes.}
%The second dimension characterizes the environment in which the systems operates.
When designing adaptive learning systems one needs to consider, what is the source of drift in data, as different adaptive learning algorithms may be better suited for handling different types of changes.
Data may change due to evolution in individual preferences (a person used to like accordion and jazz music earlier, but does not like it any more),
a population change (in time of a crisis everybody tend to get lower salaries),
adversary actions (new actions are tried to overcome the security system aiming to commit credit card frauds), or
complexity of the environment (in automated vehicle navigation the environment is so complex that
it is not feasible to take into account all possibilities of landscape deterministically, thus the environment is assumed to be changing).

In addition to types of drifts, it is important to consider, in which patterns changes are expected to occur in the future.
Patterns of changes can be categorized according to the transition speed from one concept to another into sudden, or gradual.
A drift can include a combination of multiple changes, for instance incremental drift features small steps of sudden changes, resulting in a trend.
In terms of reoccurrence drifts can be categorized into novel, or reoccurring concepts.
%This list is not exhaustive, but includes the main types.
%, which are presented in Figure~\ref{fig:cd_types}.
%\begin{figure}
%\centering
%\begin{tabular}{cc}
%\includegraphics[width=0.3\textwidth]{figures/cd_types_speed} &
%\includegraphics[width=0.3\textwidth]{figures/cd_types_reoc}
%\end{tabular}
%\caption{Types of changes.}
%\label{fig:cd_types}
%\end{figure}
% I think this is not the key to the paper, now it is in the survey.

Finally, it is advisable to consider, to what extent future changes may be predictable in a particular application.
Concept drift can be completely unpredictable (e.g.\ evolution of the financial markets),
somewhat predictable or identifiable (e.g.\ an upcoming financial crisis may be anticipated using a signal from external early warning systems),
or the environment might be well identifiable due to seasonality, or reoccurring contexts (e.g.\ an increase sales of ice-cream in summer).

\subsubsection{Operational settings}
%The third dimension that describes concept drift application tasks is related to the operational settings of the task.
determine availability of the ground truth in an online operation, such as, arrival of true labels in classification, or true target values in regression tasks.
Labels may become known immediately in the next time step after casting the prediction (e.g.\ food sales prediction).
Labels may arrive within a fixed or variable time lag (in credit scoring typically the horizon of bankruptcy prediction is fixed, for instance,
to one year, thus true labels become known after one year has passed).
Alternatively, the setting may allow to obtain labels on demand (e.g.\ in spam categorization we can ask the user the true status of a given message).

Requirements for the speed of decision making need to be considered when selecting, which algorithms to deploy.
In some applications prediction decisions may be required immediately (fraud detection), the sooner the better,
while for other analytical decisions timing may be more flexible (e.g.\ credit scoring decision may reasonably take one-two weeks).

The cost of errors is an aspect to consider when selecting an evaluation metric for monitoring of performance.
In traditional supervised learning different types of errors (e.g.\ false positives, false negatives) may resolve to different losses.
In some applications prediction accuracy may be the main performance metric (e.g.\ in online mass flow prediction),
in other applications accurate and timely identification of changes as well as accurate prediction are important (e.g.\ in demand prediction).
In the online setting, discrepancies in time may as well have associated error costs (for instance, too early prediction of a peak in food sales would still allow to sell the extra products later, but too late prediction would lead to throwing away the excess products).

Finally, the ground truth labels may be objective based on clearly defined and accepted rules (e.g.\ bankrupt or not bankrupt company) or subjective,
based on a personal opinion (e.g.\ interesting or not interesting article). % i.e. (objective vs.\ subjective), what else to this?
Alternatively, the true labels may not be available at all being impossible or too costly to measure or define in a direct way.

Table~\ref{tab:props} summarizes the identified properties of the concept drift application tasks.
The identified properties are relevant for describing the type of task, the
associated environment and the operational settings of an application under consideration.
This information is essential to determine the characteristics that the adaptive learning system needs to possess, the properties that must be prioritized when designing such a system and the evaluation criteria of the system performance.
\begin{table}[h]
\centering
\caption{Summary of properties of concept drift applications.}
%\includegraphics[width=0.8\textwidth]{props1}
{\footnotesize
\begin{tabular}{|l|l|l|}
            \hline
    \multirow{7}{*}{\begin{sideways}\textbf{Data and task}\end{sideways}}
    \multirow{7}{*}{\begin{sideways}\end{sideways}}
            & \multicolumn{1}{p{10cm}|}{}\\
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{task}}: prediction, classification, detection, clustering, itemset mining;} \\%\cline{2-3}
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{input data type}}: time series, relational, graph, bags or mix;} \\%\cline{2-3}
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{incoming data}}: stream, batches, collection iterations on demand;} \\%\cline{2-3}
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{complexity}}: volume; multiple scans; dimensionality;} \\
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{missing values}}: unlikely, random, systematic;} \\
            & \multicolumn{1}{p{10cm}|}{}\\
            \hline

    \multirow{8}{*}{\begin{sideways}\textbf{Characteristics} \end{sideways}}
    \multirow{8}{*}{\begin{sideways}\textbf{of changes}\end{sideways}}
            & \multicolumn{1}{p{10cm}|}{}\\
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{change source}}: adversary activities, changes of preferences, } \\
            & \multicolumn{1}{p{10cm}|}{\textcolor[rgb]{1.00,1.00,1.00}{empty } population change, complex environment;} \\
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{change type}}: sudden, incremental, gradual, reoccurring;} \\
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{change expectation}}: unpredictable, predictable, identifiable (meta);} \\
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{change visibility}}: direct/indirect; visual inspection, ground truth,}\\
            & \multicolumn{1}{p{10cm}|}{\textcolor[rgb]{1.00,1.00,1.00}{empty } external source, result of statistical hypothesis testing;} \\%related to labeling (of change points) or the ground truth wrt change points, i.e. it is like for label availability, but for change points
            & \multicolumn{1}{p{10cm}|}{}\\
            \hline
    \multirow{6}{*}{\begin{sideways}\textbf{Operational}\end{sideways}}
    \multirow{6}{*}{\begin{sideways}\textbf{settings}\end{sideways}}
            & \multicolumn{1}{p{10cm}|}{}\\
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{label availability}}: real time, on demand, fixed lag, variable lag;} \\%\cline{2-3}
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{decision speed}}: real time, analytical;} \\%\cline{2-3}
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{costs of mistakes}}: balanced, unbalanced;} \\%\cline{2-3}
            & \multicolumn{1}{p{10cm}|}{\textbf{\emph{true labels}}: objective, subjective;} \\
            & \multicolumn{1}{p{10cm}|}{}\\
             %\ttfamily xxx & \ttfamily xxx & \ttfamily xxx \\
            \hline
\end{tabular}
}
\label{tab:props}
\end{table}
%\begin{itemize}
%\item Data
%    \begin{itemize}
%    \item task: detection, classification, prediction, ranking;
%    \item input data: time series, relational, graph, bags or mix;
%    \item incoming data: stream, batches, collection iterations on demand;
%    \item complexity: volume; multiple scans; dimensionality;
%    \item missing values: unlikely, random, systematic;
%    \end{itemize}
%\item Changes
%    \begin{itemize}
%    \item change source: adversary, preferences, population change, complex environment;
%    \item change type: sudden, incremental, gradual, reoccurring;
%    \item change expectation: unpredictable, predictable, identifiable (meta);
%    \end{itemize}
%\item Operational settings
%    \begin{itemize}
%    \item label speed: real time, on demand, fixed lag, variable lag;
%    \item decision speed: real time, analytical;
%    \item costs of mistakes: balanced, unbalanced;
%    \item ground labels: hard, soft;
%    \end{itemize}
%\end{itemize}



\subsection{A landscape of concept drift application areas}
Now as we have identified the properties that characterize concept drift application tasks,
our next goal is to categorize application areas, and present typical applications for each category.
%We start with a grouping of the application areas and their characteristics.
%Then we map the application areas within the three dimensions, along which we organized the properties of application tasks.

We recall application domains, where data mining already plays an important role, or it has a high potential to be deployed.
For surveying and summarizing the application domains we combine the taxonomies from the ACM classification\footnote{\url{http://www.acm.org/about/class/ccs98-html}}
and KDnuggets polls\footnote{\url{http://www.kdnuggets.com/polls/2010/analytics-data-mining-industries-applications.html}}.

Table~\ref{tab:industries} presents our categorization of applications within the identified industries.
We group different application areas into three application blocks:
\begin{enumerate}[(a)]
\item monitoring and control,
\item information management, and
\item analytics and diagnostics.
\end{enumerate}
%\emph{personal assistance and information},
%\emph{management and strategic planning},
%and \emph{}
%and \emph{ubiquitous environment applications}.
For a compact representation each industry (rows) is assigned a group of applications that share common supervised learning tasks.
As it can be seen from the table, for each of the industries or groups of industries, more than one application type can be relevant.
\hyphenpenalty=10000
\begin{table} [h]
\centering
\caption{Categorization of applications by type and industry.}
  \begin{tabular}{|P{2.31cm}|*{4}{P{3.0cm}|}}\hline

    \backslashbox[2.2cm]{\textbf{Indust.}}{\textbf{Appl.}}%Types of applications
    &{\textbf{Monitoring and control}}
    &{\textbf{Information management}}%Personal assistance/Personalization
    &{\textbf{Analytics and diagnostics}}
  %  &{Ubiquitous applications}
		\\\hline

    \textbf{Security, Police}
    &fraud detection, insider trading detection, adversary actions detection
    &next crime place prediction
    &crime volume prediction
% &authentication, Intrusion detection
    \\\hline

    %\textbf{Finance, Banking, Telecom, Credit scoring, Insurance, Direct marketing, Retail, Advertising, e-Commerce}	
    \textbf{Finance, Banking, Telecom, Insurance, Marketing, Retail, Advertising}	
    &monitoring \& management of customer segments, bankruptcy prediction	
    &product or service recommendation, including complimentary, user intent or information need prediction	
    &demand prediction, response rate prediction, budget planning	
%  &location based services, related ads, mobile apps
    \\\hline

    \textbf{Production industry}
    &controlling output quality
    &--
    &predict bottlenecks
%    &managing production process
    \\\hline

    \textbf{Education (e-Learning, e-Health), Media, Entertainment}
    &gaming the system, drop out prediction	
    &music, VOD, movie, news, learning object personalized search \& recommendations
    &player-centered game design, learner-centered education	
%  &virtual reality, simulations
    \\\hline
  \end{tabular}
%\textbf{IZ: add a line 'production industry: controlling quality of output, -, -,managing production process'} }
%\includegraphics[width=0.95\textwidth]{industries}
\label{tab:industries}
\end{table}
\hyphenpenalty=10

%Types of apps
%Industries	Monitoring/control	Personal assistance/personalization	Management and planning	Ubiquitous applications
%Security, Police	Fraud detection, insider trading detection, adversary actions detection 	--------	Crime volume prediction	Authentication, Intrusion detection
%Finance, Banking, Telecom, Credit Scoring, Insurance, Direct Marketing, Retail, Advertising, e-Commerce	Monitoring \& management of customer segments,
%bankruptcy prediction	Product or service recommendation, including complimentary	Demand prediction, response rate prediction, budget planning	Location based services, related ads, mobile apps
%Education (higher, professional, children, e-Learning)  Entertainment, Media 	Gaming the system,
%Drop out prediction	Music, VOD, movie, learning object recommendation, adaptive news access, personalized search	Player-centered game design, learner-centered education	Virtual reality, simulations


%\begin{enumerate}
%\item Humanities and social sciences (education, law, music, sports):
%learning music playing style, modeling students knowledge or
%preference, crime prediction
%\item Computer science (NLP, DL, Computer vision, Signal processing):
%Intelligent web services, sentiment analysis, content (re)organization,
%face and gesture recognition, handwriting analysis
%\item Trade and Manufacturing (Manufact., Publishing, Robotics ), marketing:
%Industrial automation , Office automation, Business management,
%\item Finance, Space, Transportation
%\item Location, environment, military, other:
%Remote sensing, Cartography, Surveillance, Environment
%monitoring, weather and climate modeling,
%\item Life Sciences and medicine (biology and genetics)
%\end{enumerate}

The \emph{monitoring and control} block mostly relates to the detection tasks, where an abnormal behavior needs to be signaled.
It includes such tasks as detection of adversary activities on the web,
computer networks,
telecommunications,
financial transactions.
In most of these tasks the normal behavior is modeled and the goal is to alarm when an abnormal behavior is observed.
%E-mail and web spam detection is though can be considered as a traditional two class classification when labels from both classed are somehow available.
%examples
%\textbf{IZ: What does the above sentence say?}

The \emph{information management} applications address personalized learning, they include (web) search, recommender systems, categorization and organization of textual information, customer profiling for marketing, personal mail categorization and spam filtering.

The \emph{analytics and diagnostics} block includes predictive analytics and diagnostics tasks, such as evaluation of creditworthiness, demand prediction, drug resistance prediction.

%The \emph{ubiquitous environment} applications include a wide spectrum of moving and stationary systems, which interact with changing environment, for instance moving robots, mobile vehicles, smart household appliances.

%We consider characteristic application examples for each of the application type in Section~\ref{sec:discussion}.
%Before doing that, we consider mapping of properties identified and categorized in Section~\ref{sec:properties}.

%\subsection{Properties of the learning tasks within the application areas}

%\subsection{Linking properties of the tasks with the application areas}

After identifying three blocks of application areas,
we now assign the most likely properties to the respective application areas based on our subjective judgement. Table \ref{tab:properties} presents the assignment of the properties.


%Application examples - mostly bottom up approach some of works provide tailored solutions, some use generic approaches.
\begin{table}[htb]
\centering
\caption{Mapping between properties and application areas.}
{\footnotesize
\setlength{\tabcolsep}{1pt}
\begin{tabular}{|p{2.5cm}|p{3cm} p{3cm} p{3cm}|}
\hline
   & \textbf{Monitoring}    & \textbf{Information}   & \textbf{Analytics and}  \\%          & \textbf{Ubiquitous} \\
            & \textbf{and control}       & \textbf{management}       &  \textbf{diagnostics} \\
						\hline
&\multicolumn{3}{c|}{\emph{\textbf{Task}}} \\
\hline
\textbf{task} & detection,      & prediction      & prediction         \\%   &  \\
            & prediction      & ranking         & classification      \\%                & prediction \\
            \hline
\textbf{input data}  & sequential    & relational            & time series      \\ %     &
									&               & transactional         &  sequential        \\
									&								&												& relational \\
									\hline
\textbf{incoming}    & stream        & batches               & stream          \\ %      & stream \\
            &               &                       & iterations         \\%   & \\
            \hline
\textbf{volume}      & high          & moderate              & moderate     \\%         & high \\
\hline
\textbf{multiple scans}& no/yes          & yes                   & yes      \\%             & no \\
\hline
\textbf{missing values}& random      & unlikely              & systematic    \\%        & random \\
\hline
&\multicolumn{3}{c|}{\emph{\textbf{Environment}}} \\
\hline
\textbf{change source}& adversary    & preferences           & population     \\ %       &  \\
            &   complex            & contextual                    &         \\ %              & environment \\
            \hline
\textbf{change type} & sudden        & gradual               & incremental     \\ %      & all \\
            &               & incremental           & reoccurring          \\ % & \\
            \hline
\textbf{expectations}& unpredictable & unpredictable         & identifiable   \\ %       & unpredictable \\
            &               & predictable           & unpredictable         \\ % & identifiable \\
\hline
&\multicolumn{3}{c|}{\emph{\textbf{Operational settings}}} \\
\hline
\textbf{label speed} & fixed lag     & on demand             & real time     \\ %        & fixed lag \\
%costs of mistakes& unbalanced& balanced             & balanced           \\ %   & balanced \\
\textbf{ground labels}& objective         & subjective                  & objective            \\%      & hard \\
\hline
\end{tabular}
}
\label{tab:properties}
\end{table}

We acknowledge that contradictory examples within each area are always possible to find, yet we believe that the identified properties are the most common for given areas.

It should be noted also that this summary is aimed to cover the majority of cases that would be traditionally associated with applications of machine learning, data mining, and pattern recognition, in which the term concept drift was originally coined and studied most. More recent examples of big data applications in web information retrieval and recommender systems also fit well to our categorization.
However, the wider adoption of the big data perspective in other research areas and application domains may bring new interesting aspects. Thus, e.g.\ handling concept drift has been recognized as an important problem in process mining research dealing with the different kinds of analysis of (business) processes by extracting information from event logs recorded by an information system~\cite{DBLP:conf/ida/CarmonaG12,BoseAZP13}


%\textbf{add:} corporate financial risks, BRICS 2013 competition, PAKDD competition on credit scoring, explain credit scoring as one of the examples, e.g. instead of food sales prediction. Refs. by Hand and others suggested by Joao.



%\subsection{The map of concept drift application tasks}
%
%In Figure~\ref{fig:categorization} we map the properties with the application areas.
%The goal is to identify distinct groups of tasks in relation to application areas that share common characteristics.
%\begin{figure}
%\centering
%\includegraphics[width=0.8\textwidth]{categorization5}
%\caption{Categorization and properties of concept drift applications.}
%\label{fig:categorization}
%\end{figure}
%
%%\subsection{Using the proposed framework}
%
%To frame concept drift application tasks we consider four dimensions:
%(a) properties of tasks (Table~\ref{tab:props}),
%(b) categorization of applications (Table~\ref{tab:industries}),
%(c) the link between tasks and applications (Table~\ref{tab:properties}),
%(d) the map of concept drift application tasks (figure~\ref{fig:categorization}).
%
%Given an application task that exhibits the problem of concept drift we suggest first to identify the properties of the task including the prediction task and associated metrics of success (aka KPI's), operational settings, and the environment.
%
%%Figure~\ref{fig:steps} shows the process of deciding on an appropriate problem formulation and concept drift handling mechanism assembling.
%Our categorization summarized in Figure~\ref{fig:categorization} and elaborated further in tables~\ref{} is aimed to assist in this process. %At each step a practitioner or a researcher can look up for a ...
%We believe that this categorization can help not only to better understand the requirements of particular application task and to identify suitable state-of-the-art approaches to be used in practice, but also identify the possible gaps. %, i.e.\
%%
%%We consider characteristic examples of concrete applications in which the problem of concept drift has been addressed following the simple steps depicted in Figure~\ref{fig:steps} and highlighting the peculiarities of the each example.
%%But first,
%Next Section presents an overview on handling concept drift in real application scenarios placing this work in one of the three major application task categories.
%
%%\begin{figure} [h]
%%\centering
%%\includegraphics[width=0.50\textwidth]{steps}
%%\caption{Deciding on a concept drift handling mechanism selection.}
%%\label{fig:steps}
%%\end{figure}
%
%%We consider the following characteristic examples (different tasks, operational settings, expectations etc) placing them to this figure?

In the following section we overview application oriented studies on learning from evolving data and through considered examples illustrate peculiarities of handling concept drift under different application settings.


\section{An overview of application oriented studies on learning from evolving data}
\label{sec:applications}
Following the categorization of applications, we distinguish three main groups of application tasks: monitoring and control, information management, and diagnostics. Besides having different goals, the groups also differ in data types. Monitoring and control applications typically use streaming sensory data as inputs, concept drift typically happens fast and suddenly.
Information management applications work with time-stamped documents, concept drift happens slower than in the previous case, changes can be sudden or gradual.
Diagnostics applications typically use relational data tables, where observations are time-stamped. Concept drift, also known as population drift, typically happens slowly. Changes are typically incremental, or evolving. Sudden shifts are not very typical in these applications.

In this section we briefly characterize each group, overview application studies that fall within each group and touch upon the issue of concept drift, and present three studies in more detail, illustrating how the prediction task is formulated, and how concept drift is handled.
%Next we provide an elaborate discussion on three application examples, corresponding to group of application tasks.
We discuss research challenges, and highlight interesting aspects of these application tasks from concept drift handling perspective

We do not claim that this is an exhaustive list of concept drift applications.
Our goal is to include examples from a wide range of application tasks.

% for the next revision we do need to have a summary that would tell which of the four CD handling approaches was used and what was special in each paper, what was evaluated, how realistic the exp. setup wrt operational settings - could be good to have
%Table \ref{tab:applications} summarizes application oriented studies, which present tasks requiring adaptive learning models.
%\subsection{New references}
%collaborative filtering with temporal dynamics \cite{Koren10}
%classification of biomedical articles \cite{Haidar10}
%smart home \cite{Martin10}
%predicting experience multimedia streaming \cite{Menkovski09} Vlado
%ECML2010: P2P and cd with new concept/class identification papers. <- Vivek, artificial data, does not count :p

\subsection{Monitoring and Control}

The first group of concept drift application tasks aim at real-time monitoring or control of some automated activity, for example, operation of a chemical plant. Input data typically consists of streaming sensory readings, and the target is often related to describing the quality of the activity or process. The goal of such monitoring could be to oversee operation of the system (without interfering, unless something goes wrong), to control the system, or to detect abnormal behaviour (possibly due to adversary actions).  Concept drift typically happens fast (in the order of seconds or minutes), and changes are sudden. Table \ref{tab:mon_con} summarizes example studies related to handling concept drift  in monitoring and control applications.
\begin{table}[t]
\caption{Summary of monitoring and control studies.}
\centering
{\footnotesize
\begin{tabular}{|llll|}
\hline
\textbf{Goal} & \textbf{Domain} & \textbf{Application task} & \textbf{References} \\
\hline
		& transportation & traffic management & \cite{Crespo05,Moreira08}\\
\textbf{Monitoring} & remote sensing & place, activity recognition & \cite{Zhou08,Luo07,Liao07}\\
\textbf{for} & production industry & production quality control & \cite{PechenizkiySIGKDDExpl09,Kadlec11ache}\\
\textbf{management} & telecom. network & telecommunication monitoring & \cite{Pawling07}\\
\hline				
		& mobile systems & controlling robots, vehicles & \cite{Thrun06,Procopio09,Lattner06}\\
\textbf{Automated}  & smart home & intelligent appliances & \cite{Rashidi09,Anguita01}\\
\textbf{control} & virtual reality & computer games, flight simulators & \cite{Charles05,Harries98}\\
\hline
	& computer security & intrusion detection & \cite{Lee00}\\
\textbf{Anomaly} & telecommunications & intrusion detection, fraud & \cite{Mazhelis07,Hilas09} \\
\textbf{detection} & finance & fraud, insider trading & \cite{Bolton02,Donoho04}\\
\hline
\end{tabular}
}
\label{tab:mon_con}
\end{table}

\subsubsection{Monitoring for management.}

Monitoring for management tasks are often  found in production industry and transportation domains.
Concept drift is typically observed due to complexity of the process, or human (operators) factors. So many factors are affecting the process, that it is not possible to take all of them in the predictive model. When some of those factors, that have been fixed for a while, suddenly change - a concept drift is observed. For example, production quality in a chemical plant may be different depending on the supplier of raw materials. If we make a model when one supplier is used, such a model may not be as accurate when the supplier changes, and some adaptation may be required.

In transportation, traffic control centers use data driven traffic management systems for predicting traffic conditions~\cite{Crespo05}, such as car density in a particular area, or anticipating traffic accidents.
Public transportation travel time prediction~\cite{Moreira08} is used for scheduling and human resource (drivers) planning purposes.
In remote sensing relevant application tasks include place recognition~\cite{Luo07}, activity recognition~\cite{Liao07},
interactive road segmentation~\cite{Zhou08}.
In production industry relevant tasks include monitoring the output quality, for example, in chemical production \cite{Kadlec11ache}, or the process itself, for example, boilers producing heat~\cite{PechenizkiySIGKDDExpl09}.
Monitoring models in production industry are called \emph{soft sensors} \cite{Kadlec11}.
In~\emph{service monitoring} detection of defects or faults in telecommunication network~\cite{Pawling07} present relevant tasks.

\subsubsection{Automated control.}

In automated control applications the problem of concept drift is often referred to as the dynamically changing environment.
The objects learn how to interact with the environment and since the environment is too complex to take all the playing factors into a predictive model, therefore predictive models need to be adaptive.

Examples of application domains in automated control include: mobile systems and robotics, smart homes, and virtual reality.
Ubiquitous knowledge discovery deals with distributed and mobile systems, operating in a complex, dynamic and unstable environment.
The word 'ubiquitous' means distributed at a time.
Relevant tasks include navigation systems \cite{Thrun06}, soccer playing robots \cite{Lattner06}, vehicle monitoring, household management systems, music mining are examples.
Intelligent systems, or smart home systems \cite{Rashidi09} aim to develop intelligent household appliances \cite{Anguita01}.
Virtual reality includes application tasks in computer game design \cite{Charles05}, where adversary actions of the players (cheating) or improving skills of a player, may be cause concept drift. Virtual reality is also used in flight simulators, where skills and strategies change from user to user \cite{Harries98}.


\subsubsection{Anomaly detection.}

Anomaly detection is often tackled as one class classification task,
where the properties of a normal behavior are well defined, while the properties of abnormal behovior may be changing.
%The classes are typically highly imbalanced with a few real attacks.
Concept drift happens due to changes in behavior, characteristics of legitimate users, or new creative adversary actions.

Anomaly detection is very relevant for computer security domain, in particular, network intrusion detection \cite{Lee00}.
In telecommunications fraud prevention \cite{Hilas09} or mobile masquerade detection~\cite{Mazhelis07} are the relevant tasks.
In finance data mining techniques are employed to monitor streams of financial transactions
(credit cards, internet banking) to alert for possible frauds or insider trading~\cite{Sudjianto10,Becker10,Hand10}.

\subsubsection{Credit scoring.}
In retail banking, credit risk assessment often relies in credit scoring models developed with supervised learning methods used to evaluate a persons credit worthiness. The output of these models is a score that translates a probability of a customer becoming a defaulter, usually in a fixed future period, so-called scoring or PD models . Nowadays, these models are at the core of the banking business, because they are imperative in credit decision-making, in price settlement, and to determine the cost of capital. Moreover, central banks and international regulation have dramatically evolved to a structure where the use of these models is implicit, to achieve sound standards for credit risk valuation in the banking system.

Developing and implementing a credit scoring model can be time and resources consuming  easily ranging from 9 to 18 months, from data extraction until deployment. Hence, it is not rare that banks use an unchanged credit scoring model for several years (a 5 year period is commonly exceeded). Bearing in mind that models are built using a sample file frequently comprising 2 or more years of historical data, in the best case scenario, data used in the models are shifted 3 years away from the point they will be used. An 8-years shift is frequently exceeded. Should conditions remain unchanged, then this would not significantly affect the accuracy of the model, otherwise, its performance can greatly deteriorate over time. The recent financial crisis came to confirm that financial environment greatly fluctuates, in an unexpected manner, posing renewed attention regarding scorecards built upon frames that are by far outdated. By 2007-2008, many financial institutions were using stale scorecards built with historical data of the early-decade. The degradation of stationary credit scoring models is an issue with empirical evidence in the literature\cite{crook92,HandA14}, however research is still lacking application oriented solutions.


\subsubsection{Example study: online mass flow estimation.}

Industrial boilers are used for heating buildings in winter times. Some boilers operate on biofuel, which is a mix tree branches, peat and  plants; the mix is not necessarily uniform and the proportions may vary. The authors of the first example study~\cite{PechenizkiySIGKDDExpl09} consider the problem of online mass flow estimation in boiler operation.
During burning phase the mass of fuel inside the boiler container decreases, and as new fuel is added to the container, while at the same time the burning process continues, the fuel feeding phase starts that is reflected by a rapid mass increase.

Input data comes from physical sensors with a negligible  lag.
The task is to estimate the current mass flow (similarly to fuel consumption indicators in passenger cars), and detect the points of phase switch in real time.

%The problem is to predict online mass flow that can be
%done by estimating each moment in time what the current amount of fuel in the bunker is.
%\begin{figure} [h]
%\centering
%\includegraphics[width=0.60\textwidth]{data_capture}
%\caption{The origin of the input mass measurements signal.}
%\label{fig:data_capture}
%\end{figure}

There are three main sources of drifts in the signal (an exsample is depicted in Figure \ref{fig:sig}).
First, fuel feeding is manual and non-standardized process, which is not necessarily smooth and may have short interruptions.
%Each operator can have different habits. Besides, the feeding speed depends on the type of fuel used.
Second, rotation of the feeding screw adds noise to the measured signal.
%Besides, fuel particle jamming often happens, slowing down the screw for some seconds
%and distorting the signal estimate. Therefore, the reported mass inside the bunker
%is not accurate, the signal contains extreme upward outliers in the original signal,
%that can be seen in Figure~\ref{fig:changeprop}.
Finally, there is a low amplitude rather periodic noise, which is caused by the mechanical rotation of the system parts, the magnitude of this noise depends on operational setting.
%These amplitudes may become higher depending on the burning setup.
\begin{figure}[t]
\centering
\begin{tikzpicture}[scale = 0.6]
\begin{axis}[hide x axis, hide y axis, width = 20cm, height = 5.5cm]
\addplot[color=red, line width = 1pt] table[x=sk,y=boil] {boiler.dat};
\end{axis}
\end{tikzpicture}
\caption{An example of boiler data.}
\label{fig:sig}
\end{figure}

%\textbf{Task. }
%Thus, even though the ultimate goal is to estimate the mass flow that can be formulated as a regression problem,
The main focus is on constructing a learning system that can deal with two types of change points:
an abrupt change to feeding and slower but still abrupt switch to burning,
and asymmetric outliers, %(see Figure~\ref{fig:changeprop} left),
which in online settings can be easily mixed with the changes to feeding.
%Besides there is a symmetric high frequency signal noise.
These change points need to be identified in real time, and they should not be mixed with noise.
When these regime switch points are known, a new predictive model can be incrementally started after each feed to reflect the most recent fuel characteristics.

The optimization criteria for change detection is to minimize the detection delay (from the actual change point to detection), and minimize the number of false alarms, when an outlier is singled as a change.  All true change points have to be detected, no  misses are allowed.
In addition, the final performance indicator is the mean square error (MSE) of the mass flow estimation. It is critical for algorithm design to understand, how different types of errors in detection affect the overall accuracy of classification. Such sensitivity analysis can be performed by varying the detection thresholds.
% KPI - MSE of the estimated signal we need to understand how accurately we identify the change points in terms of TP/FP rates and lag/delay in the identification of change points. Last but not least we may like to know how different types of errors affect the overall accuracy of classification.
%\begin{figure}[th]
%\centering
%\includegraphics[width=0.48\textwidth]{onesidedoutliers}
%\hfill
%\includegraphics[width=0.48\textwidth]{interchanges}
%\caption{Peculiarities in the data: upward outliers %due to jamming of the screw
%(left) and short burning periods within the feeding stage (right).}
%\label{fig:changeprop}
%\end{figure}

%\textbf{Selection of the concept drift handling approach. }

% IZ: commented out, it sounds too generic.
%Algorithmic change detection is not trivial as it might seem from visual inspection of the signal.
%The asymmetric nature of the outliers would elevate the original signal if approximated directly,
%since there are no corresponding negative outliers.
%In other words, the noise and outliers do not sum to zero with respect to the true signal.
%
%Besides, there are short burning periods within feeding stages,
%due to possible pauses in feeding (see Figure~\ref{fig:changeprop} right),
%which depend on human factor. These interruption regimes can vary from ~5 to 20 seconds and
%are difficult to discriminate.
%
%In addition, we need to take into account that the mass flow signal may have
%a non-zero second derivative, i.e. the speed of the mass change depends on the amount
%of fuel in the container -- the more fuel is in the container, the higher is the acceleration, thus
%the more fuel gets into the screw.
%The weight of the fuel at higher levels of the tank compresses
%the fuel in the lower levels and in the screw, and the fuel density is increased.
%Besides, compression and thus the burning speed depends on the type and quality of the fuel.
%
%Thus, on the one hand we need to take data properties into consideration for handling changes in the data.
%However, on the other hand we can simplify the detection task making the explicit assumptions
%about the anticipated changes and states in which the system may be.

Evaluation of the performance of the algorithms is challenging, since there is no ground truth available. The authors construct an approximation to the ground truth, and use it for the evaluation purposes in online settings (only in the experiments, but not in real operational setting). Absence of ground truth is a common problem in monitoring applications, since, if it was easily available, there would be no need for the predictive model, which is being designed.

%, but the evaluation will be biased to the ground truth approximation process. However, in this application we know how many sudden change points are present and constructing a benchmark dataset we can mark all of them and evaluate how quickly, and how accurately we can detect each of it. We can inspect visually and measure experimentally the effect of skipping a change point, or detecting it too late, or detecting it inaccurately, i.e.\ before change actually happened, or after it, or the effect of generating a false alarm to the performance of the estimator itself. See Appendix B for a few illustrative examples.

\subsection{Information management}

These tasks aim at organizing, and personalizing information.
Typically, data is comes as time stamped entities, for instance, web documents,
and the goal is to characterize each entity.
Information management application tasks can be further split into personal assistance, marketing, and management tasks.
Concept drift happens not so fast (in the order or days or weeks), changes could be sudden or gradual.
Table \ref{tab:inf_man} summarizes example studies related to handling concept drift  for information management.
\begin{table}[t]
\caption{Summary of information management studies.}
\centering
{\footnotesize
\begin{tabular}{|llll|}
\hline
\textbf{Goal} & \textbf{Domain} & \textbf{Application task} & \textbf{References} \\
\hline
		& text processing & news categorization, & \cite{Widyantoro05,Billsus99,Lebanon08,Mourao08} \\
		& & document classification & \\
\textbf{Personal}& 			& spam filtering & \cite{Delany06,Riverola07} \\
\textbf{assistance}& web mining & web personalization & \cite{Scanlan08,Silva07,deBra03} \\
		& & library, media search & \cite{Hasan08,Flasch07} \\
\hline	
		& customer segmentation & customer segmentation,  &	 \cite{Crespo05,Black02,Lathia08,Rozsypal05} \\
		& 	& profiling & \\
\textbf{Marketing}& recommender systems & movie recommendations & \cite{Koren10,Ding05} \\
\hline
\textbf{Management}& project management & software project mgmt. &  \cite{Ekanayake09} \\
			& archiving & article, mail organization & \cite{Yang06,Kleinberg02} \\	
\hline		
\end{tabular}
}
\label{tab:inf_man}
\end{table}

\subsubsection{Personal assistance.}

Personal assistance applications aim at user modeling.
The goal is to personalize information flow, the process is often referred to as information filtering.
A rich technical presentation on user modeling can be found in \cite{Gauch07}.
One of the primary applications of user modeling is representation of queries, news,
blog entries with respect to \emph{current} user interests.
Changing user interests over time is the main cause of concept drift.

Large part of personal assistance applications are related to handling~\emph{textual data}, example tasks include
news story classification \cite{Widyantoro05,Billsus99}, or document categorization \cite{Lebanon08,Mourao08}.
In web search, detecting changes in user satisfaction has been recognized to be important \cite{Kiseleva:2014}.
Personal assistance tasks relate to other types of data, such as networked multimedia, music, video, as well as digital libraries \cite{Hasan08}.
Large body of applications relate to web personalization and dynamics \cite{Scanlan08,Silva07,deBra03},
where interim system data (logs) is mined.

%Finally, concept drift problem is highly relevant for spam filtering \cite{Delany06,Riverola07}.
%First of all there are adversary actions (spamming) in contrast to the personal assistance
%applications listed before.
%It means that the senders are actively trying to overcome the filters therefore the content changes rapidly.
%Adversaries are intelligent and adaptive.
%Spam messages are disjunctive in content.
%Spam types are subject to seasonality and popularity of the topics or merchandize.
%There is a drift in the amount of spam over time, as well as in the content of the classes \cite{Fawcett03}.
%Besides, personal interpretation of what is spam might differ and change.

\subsubsection{Marketing.}

Customer profiling applications use aggregated data from many users.
The goal is to segment customers based on their interests and needs.
Concept drift happens due to changing individual interests and behavior over time.

Relevant tasks include direct marketing, based on product preferences,
for example cars \cite{Crespo05}, or service usage, for example telecommunications \cite{Black02},
identifying and analyzing shopping baskets \cite{Rozsypal05}, social network analysis for customer segmentation \cite{Lathia08},
recommender systems \cite{Koren10}.

\subsubsection{Management.}

A number of studies aim at adaptive organization or categorization of web documents, e-mails, news articles \cite{Yang06,Kleinberg02}. Concept drift happens due to evolving nature of the content.
In business software project management, careful planning may be inaccurate if concept drift is not taken into account \cite{Ekanayake09}.

\subsubsection{Example study: movie recommendation.}

%sparse matrix (1% of nonzero value) makes most of ML techniques not applicable, CF approaches are equiped with mechanisms of handling temporal dynamics including CD. Traditional sliding window approaches are not suitable for the following reasons: few data per user, relation between ratings is important disregarding how old they are

Interest of data mining community in recommender systems domain has been boosted by Netflix competition\footnote{\url{www.netflixprize.com}}. One of the lessons learnt
from it was that taking temporal dynamics is important for building accurate models.
Handling concept drift has another set of peculiarities here.
Both items and users are changing over time. Item-side effects include first of all changing product perception and popularity.
The popularity of some movies is expected to follow seasonal patterns.
User-side effects include changing tastes and preferences of customers, some of
which may be short-term or contextual and therefore likely reoccurring
(mood, activity, company, etc), changing perception of rating scale,
possible change of rater within household and alike problems.

As suggested in~\cite{Koren10} popular windowing and instance weighing approaches
for handling concept drift are not the best choice simply because
in collaborative filtering the relations between ratings is of the main importance for predictive modeling.

In this application labels are soft, data comes in batches, and the rating matrix is high-dimensional and extremely sparse containing only about 1\% of non-zero elements (that makes the application of most machine learning predictors inapplicable and boost the development of advanced collaborative filtering approaches).

%In spam classification - dynamic feature selection and compression-based featureless similarity
% perhaps here we can come back to four major types of sources (advers, complex, )


\subsection{Analytics and diagnostics}

Analytics and diagnostics tasks aim at characterizing health, well-being, or a state of humans, economies, or entities.
Data typically comes as time stamped relational data. Concept drift often happens due to population drift,
and changes are typically slow (in the order of months or years) and incremental.

Analytics and diagnostics tasks can be further split into forecasting, medicine, or security applications.
Table \ref{tab:diagnostics} summarizes example studies related to handling concept drift  in diagnostics.
\begin{table}[t]
\caption{Summary of diagnostics studies.}
\centering
\begin{tabular}{|llll|}
\hline
\textbf{Goal} & \textbf{Domain} & \textbf{Application task} & \textbf{References}\\
\hline
\textbf{Forecasting} & banking & bankruptcy prediction & \cite{Sung99,Horta09} \\
& economics & forecasting & \cite{Giacomini06,Klinkenberg05,Harries95} \\
\hline
			& drug research & antibyiotic resistance & \cite{Tsymbal08,Jermaine08,Martin12} \\
\textbf{Medicine}&			 & drug discovery & \cite{Forman02} \\
			 & clinical research & disease monitoring &  \cite{Kukar03,Gago07,Black04} \\
\hline
\textbf{Security}& biometrics & authentication & \cite{Yampolskiy07,Poh09} \\
\hline
\end{tabular}
\label{tab:diagnostics}
\end{table}

Changes happen due to changing environment, such as economic situation, which includes a large number of influencing factors.

\subsubsection{Forecasting.}

Forecasting applications typically relate to analytics tasks in economics and finance, such as macroeconomic forecasting,
demand prediction, travel time predictions, event prediction (e.g.\ crime maps, epidemic outbreaks).
Changes over time often happen due to population drift, which typically happens much slower,
than, for instance, changes in personal preferences in information management applications, or adversary actions in monitoring applications.

In finance relevant tasks include bankruptcy prediction or individual credit scoring \cite{Sung99,Horta09},
in economics concept drift appears in making macroeconomic forecasts \cite{Giacomini06},
predicting phases of a business cycle \cite{Klinkenberg05}, or stock price prediction \cite{Harries95}.

\subsubsection{Security.}

In biometric authentication~\cite{Yampolskiy07,Poh09} concept drift can be caused by changing physiological factors, e.g.\ growing a beard.

\subsubsection{Medicine.}

Medicine applications, such as antybiotic resistance prediction, or predicting epidemic outbreaks or nosocomial infections, may be subject to concept drift due to adaptive nature of microorganisms \cite{Tsymbal08,Jermaine08,Martin12}.
Clinical studies and systems need adaptivity mechanisms to changes caused by human demographics \cite{Kukar03,Gago07}.

%\subsubsection{Strategic management: Food wholesales prediction}
%
%In food sales prediction a large number of factors affect the demand.
%Designing an intelligent predictor that would beat a simple moving average
%baseline across a number of products appears to be a non-trivial task~\cite{Zliobaite10esa}.
%Sudden, gradual and reoccurring drifts are expected to happen in this domain,
%and there are numerous reasons that may cause the drift. For two obvious example
%see Figure~\ref{fig:sligro2}.
%
%%\begin{figure}[htb]
%%\centering
%%\includegraphics[width=0.80\textwidth]{sligro2}
%%\caption{Peculiarities in the data: seasonal behavior (top) and abrupt permanent drop in the sales (bottom).}
%%\label{fig:sligro2}
%%\end{figure}
%
%In general, the definition of concept drift in this application is not as obvious
%as in the boiler or the electricity load prediction examples.
%
%Some food sales timeseries often demonstrate chaotic behavior, i.e. demand is
%constantly changing and is hardly predictable at all. Other timeseries may have
%strong reoccurring patterns as in the top example in Figure~\ref{fig:sligro2}.
%
%However, as a food sales predictor learns not only from timeseries itself but typically from a richer representation (Figure~\ref{fig:sligro1}), some of such seasonal changes can be already captured by predictive or contextual features and therefore should not be regarded as a drift.
%
%%\begin{figure}[htb]
%%\centering
%%\includegraphics[width=0.80\textwidth]{sligro1}
%%\caption{Training data sources in food wholesales prediction.}
%%\label{fig:sligro1}
%%\end{figure}
%
%Sudden changes can be also caused for various reasons like for example
%a discontinuity of the product in some of the shops as illustrated in
%the bottom example in Figure~\ref{fig:sligro2}.
%
%In this example labels can be considered as hard and becoming available `immediately', i.e. before we generate next prediction (unless we have to predict a few steps ahead). However, if we blindly formulate the problem as time-series prediction, we won't take into account e.g.\ out of stock cases. Over and under prediction, as well as predicting sales with 'early' and 'late' biases have different costs associated with storage, products becoming perishable, and opportunity costs.

\subsubsection{Example study: predicting antibiotic resistance.}

Antibiotic resistance is an important problem and it is an especially difficult problem with nosocomial infections in hospitals because pathogens
attack critically ill patients who are more vulnerable to infections than the general population and therefore require more antibiotics.

Prediction model is based on information about patients, hospitalization, pathogens and antibiotic themselves.
The data arrives in batches, the labels become available with a variable lag depending on the size of the hospital and intensiveness of the patients flow. The size of the data is relatively small both in number of instances and the number of features to be considered.

The peculiarity of concept drift is that it may happen for various reasons particularly because pathogens may develop resistance and share this information with peers in different ways. Consequently, the type and severity of changes may depend on the location in the instance space. Furthermore, the drift is expected to be local and reflect e.g.\ a pathway in the hospital where the resistance was taking place and spread around.
This calls for the direct or indirect identification of the regions or subgroups in which concept drift is occurring.
Handling concept drift with dynamic integration of classifiers that takes this peculiarity into account was shown to be effective~\cite{Tsymbal08}.


\section{Discussion and Conclusions}
\label{sec:conclusion}

The main lesson in this study is related to the evolving characteristic of data and the implications in data analysis.
Nowadays, digital data collection is easy and cheap. Data analytics in applications where data is collected over time,
must take into account the evolving nature of data.

The problem of concept drift has been recognized in different application domains. Interest in different research communities has been reinforced by several recent competitions including e.g.\ controlling driverless cars at the DARPA challenge, credit risk assessment competition at PAKDD'09), and Netflix movie recommendation.

However, concept drift research field is still in an early stage.
The research problems, although motivated by a belief that handling concept drift is highly
important for practical data mining applications, have been formulated and addressed often in artificial and somewhat isolated settings.
%now this contradicts literature review, because we do not provide meta-analysis for it.
%
%This resulted in the situation that we now have generic approaches for detection and handling of concept drift,
%which have been tested primarily on simulated data or real data with simulated drift.
%Assumptions behind expected type of changes, reasons for changes were not always
%stated explicitly for these approaches.
Approaches for handling concept drift are rather diverse and have been developed from two sides -- theory-oriented and applications-oriented.
Recent studies however do highlight the peculiarities of particular
applications and give intuition and/or empirical evidence
why traditional general-purpose concept drift handling techniques
are not expected to perform well and suggest tailored or more
focused techniques suitable for a particular application type.


%The problem of concept drift has been recognized and studied in several areas of computer science related to data mining research.
%
 %By this we mean that many of the papers published in the data mining journals have been proposing new generic approaches for detecting and handling concept drift in a `typical' application setting, while testing these approaches on synthetically generated
%datasets or real datasets with artificially imputed drifts. Many other papers have been motivated by the needs (and operational settings) of specific applications and have developed tailored solutions for addressing these specific problems without questioning the generality of the developed ideas.

In this work we categorized the applications, where handling concept drift is known or expected to be an important component of any learning system.
We identified three major types of applications, identified key properties of the corresponding settings,
%We hope that our categorization will serve as a reference framework for the researchers, who
%are newcomers to the field or the researchers, who find it important to discuss in more detail the
%applicability of the proposed approach to some of the supervised learning settings.
%We surveyed application tasks where handling concept drift is relevant,
and provided a discussion emphasizing the most important application oriented aspects.
Summarizing those we can speculate that the concept drift research area is likely to refocus further from studying general methods to detect and handle concept drift to designing more specific,
application oriented approaches that address various issues like delayed labeling,
label availability, cost-benefit trade-off of the model update and other issues peculiar to a particular type of applications.

Most of the work on concept drift assumes that the changes happen in hidden context that is not observable to the adaptive learning system. Hence, concept drift is considered to be unpredictable and its detection and handling is mostly reactive.
However, there are various application settings in which concept drift is expected to reappear along the time line and across different objects in the modeled domain. Seasonal effects with vague periodicity for a certain subgroup of object would be common e.g.\ in food demand prediction~\cite{Zliobaite11sligro}.
Availability of external contextual information or extraction of hidden contexts from the predictive features may help to better handle recurrent concept drift, e.g.\ with use of a meta-learning approach ~\cite{GamaK11}. Temporal relationships mining can be used to identify related drifts, e.g.\ in the distributed or peer-to-peer settings in which concept drift in one peer may precede another drift in related peer(s)~\cite{Ang2013}.
Thus, we can expect that for many applications more accurate, more proactive and more transparent change detection mechanisms may become possible.

%Can we do it in a data driven way?

Moving from adaptive algorithms towards adaptive systems that would automate full knowledge discovery process and scaling these solutions to meet the computational challenges of big data applications is another important step for bringing research closer to practice. Developing open-source tools like SAMOA~\cite{JMLR:v16:morales15a} certainly facilitates this.

Domain experts play an important role in acceptance of big data solutions. They often want to go away from non interpretable black-box models and to develop trust in underlying techniques, e.g.\ to be certain that a control system is really going to react to changes when they happen and to understand how these changes are detected and what adaptation would happen.
Therefore we anticipate that there will be also a change in the focus from change detection to change {\em description}, from {\em when a change happen} to {\em how and why it happened} as such research would be helpful in improving utility, usability and trust in adaptive learning systems being developed for many of the big data applications.\\

%\section*{Acknowledgements}

\textbf{Acknowledgements.} This work was partially supported by European Commission through the project MAESTRA (Grant number ICT-2013-612944).

%This research is partly supported by NWO HaCDAIS and FP7 EU INFER projects. We are thankful to the contributors and participants of HaCDAIS 2010 workshop held at ECML/PKDD 2010 for their valuable comments and discussions that helped to better shape this work.

\bibliographystyle{plain}
\bibliography{bibapplications}

%\pagebreak
%\appendix
%

\end{document} 