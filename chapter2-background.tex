\chapter{Background}
% Technical details to read the rest
% Concept drift & model adaptation (Survey paper by Gama)
%gama_survey_cd_fig3.pdf
\section{Concept Drift}

In supervised learning task machine learning model predicts a target variable $y = (y_1, \dots, y_n)$ given a set of input features $x = (x_1, \dots, x_n)$.
In batch training, or, offline settings, the model $p(x, y)$ (Equation~\ref{eq:product_rule}) is trained using the fixed training data set where both $x_i$ and $y_i$ are known. 
On the inference step $x_i$ is known and model is used to predict (Equation~\ref{eq:bayes}) $y_i$ for new data samples. 
Equation~\ref{eq:product_rule}, Equation~\ref{eq:bayes}.
\begin{equation}\label{eq:product_rule}
  p(x,y) \equiv p(y|x)P(x) = p(x|y)P(y)
\end{equation}
\begin{equation}\label{eq:bayes}
  p(y | x) = \frac{p(y) p(x|y)}{p(x)}\: \text{, where}\: p(x)=\sum_{y} p(y) p(x|y)
\end{equation}.
% https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2014-69.pdf
% https://www.dropbox.com/scl/fi/hc065av32qwxptjcmde1d/CD_dagstuhl_7Sep2020.pptx?dl=0&rlkey=pjwwsmi5jcao6ygkx3yiuonkp
% Where $x_i \in \mathcal{R}^n$ elements are vectors, and the target is usually also a vector or just the number in the regression task $y_i \in \mathcal{R}^n$, or a categorical variable (e.g. ``good/bad'') in the classification tasks.  
% In the production process $x$ can be sensor readings and $y$ is a quality %measure.  

In the real world, data distributions are almost never static. 
In real world application we often deal with streaming settings.
Streaming settings are more prevalent.
For example sensor readings from medical devices, network traffic, satellite data.
A stream is an ordered sequence of examples continuously observed over time. 
An example is a pair $(x_i, y_i)$.

\textit{Concept drift}~\cite{Widmer1996,schlimmer1986incremental,gama2014survey} is a phenomenon when relation between the input data and the target variable changes over time~\cite{gama2014survey}. 
Formally concept drift (CD) can be defined~\cite{gama2014survey} by Equation~\ref{eq:concept_drift}
\begin{equation}\label{eq:concept_drift}
    \exists x: p_{t_0}(x,y) \neq  p_{t_1}(x,y).
\end{equation}
\textit{Concept} is a data distribution in a given time moment.

The commonly used approaches to cope with concept drift are \textit{i)} update the model at regular time intervals without considering whether changes have occurred (evolving models~\cite{SouzaChallenges2020}) and \textit{ii)} monitor input data stream for distribution changes and update model if change is alarmed. 
Adaptive models explicitly detect concept changes using drift detectors, updating models when changes are alarmed.  

Adaptive learning refers to updating model online to react to concept drifts~\cite{gama2014survey}.

A common approach to deal with streaming data is to analyze data within a sliding window. 
Sliding window of width $w$ represents a sample of examples indexed by $(i, i+1, \dots, i+w-1)$. 
The problem, however, is to identify $w$ value.

With regard to the transition speed concept drifts are classified as depicted on the Figure~\cite{fig:souza_cd_speeds}.
An abrupt drift is when data distribution changes near instantly.
Concepts which were seen in the past and are later observed again are called \textit{recurring concepts}.
Incremental drifts are those with intermediary concepts between initial and final concepts.
In a gradual drift probability of observing instances belonging to the initial concept decreases while probability of instances from final concept increases within transition period.

\begin{itemize}
  \item \textit{Real concept drift}\cite{gama2014survey,gao2007general, salganicoff1997tolerating} is a change in $p(y|x)$
  \item \textit{Virtual drift}\cite{delany2004case,tsymbal2004problem,widmer1993effective} is a change $P(x)$ which doesn't affect $p(y|x)$
\end{itemize}

Concepts of real and virtual drifts are illustrated by the Figure~\ref{fig:fig1_gama_survey_cd}.
Transition from one concept to another can happen in different forms over time as illustrated on Figure\ref{fig:fig2_gama_survey_cd} for one dimensional data stream.  
~\cite{karkkainen2014region}

\begin{figure}[htb!]
	\centering
	\includegraphics[height=0.15\textheight]{images/images_cropped/gama_survey_cd_fig1}
	\caption{Illustration from~\cite{gama2014survey} depicting real and virtual concept drift phenomena. Circles represent instances $x_i$, different colors - classes, dashed line is a decision boundary. }\label{fig:fig1_gama_survey_cd}
\end{figure}

\begin{figure}[htb!]
	\centering
	\includegraphics[width=0.9\textwidth]{images/images_cropped/gama_survey_cd_fig2}
  \caption{Changes between concepts can be gradual or abrupt~\cite{gama2014survey}}\label{fig:fig2_gama_survey_cd}
\end{figure}


\begin{figure}[htb!]
	\centering
	\includegraphics[height=0.15\textheight]{images/images_cropped/krop_souza_cd_speed}
	\caption{Illustration from~\cite{SouzaChallenges2020}: illustration of three types of concept drift with regard to speed of change.}\label{fig:souza_cd_speeds}
\end{figure}

\section{Illustrative examples}

Another example is, for example, ice cream demand prediction.
Demand is affected by seasons.
And obviously demand for the ice cream is higher during the summer and lower in winter time.

Another example is relevant news feed recommendations.
Covid-19 event is a concept drift example affected probably all human activities around the world, including relevant news feed.

Online mass flow prediction in CFB (Circulating fluidized bed) boiler~\cite{pechenizkiy2010online} is an example from monitoring and control application area.


\section{Concept drift adaptation}

Excellent survey~\cite{Gama2014a} provides a comprehensive overview on handling concept drift using adaptive learning methods in On-line settings.
In \textit{offline} training settings the whole training data is available at the time of training.
In \textit{online} training settings training data is not static and new training samples arrive over time and the data is usually processed sequentially.
Another case is when the whole training data is available but it doesn't fit into memory and model should be trained in incremental settings by reading data in batches from the hard drive. 

Online model is continuously updated during operation as more data arrives.
\textbf{Example:} new articles which are relevant or not relevant for a particular person.

\subsection{Requirements for adaptive models}
Predictive models which operate in dynamic environment need to have mechanisms to \textbf{detect} and adapt to evolving data, otherwise their accuracy will degrade. 
The general requirements for the model implementation are that the model should be able to:
\begin{itemize}
	\item [1)] Detect concept drifts as soon as possible, i.e. as high as possible TP rate along with small detection delays
	\item [2)] Distinguish noise from concept drift (as low as possible FA rate)
\end{itemize}
Online adaptive learning scenario is as follows.
The model is a mapping $y=\mathcal{L}^{\text{initial}}(X)$ from input variables to the target.
After initial model is trained a new example $X_t$ arrives and prediction is made $\hat{y_t} = \mathcal{L}(X_t)$.
Then, after some time, true label $y_t$ arrives and the loss $f_{loss}(y_t, \hat{y_t})$ can be estimated.
If concept drift is alarmed then model is updated to $\mathcal{L}^{\text{updated}}$ using $(X_t, y_t)$.
At some moment $\mathcal{L}^{\text{initial}}$ can be completely forgotten and replaced by $\mathcal{L}^{\text{updated}}$.
There are various scenarios how old model and training data can be handled depending on available computational and memory resources.
Figure~\ref{fig:fig3_gama_survey_cd} depicts a general architecture of adaptive learning system.
\begin{figure}[htb!]
	\centering
	\includegraphics[width=0.9\textwidth]{images/images_cropped/gama_survey_cd_fig3}
  \caption{(Figure from~\cite{gama2014survey}) 
	A generic schema of adaptive learning system.
  The memory module is responsible for which data is presented to the learning module.
  The loss estimation module computes current model performance and produces input signal for Change detection module.  
  The change detection module is a control unit which alarms a change once it is detected and triggers model and memory update procedures.
	}\label{fig:fig3_gama_survey_cd}
\end{figure}


\section{The link between change detection and concept drift}

Concept drift and change detection in time series are closely related problems.
\textit{Concept} is a set of contiguous examples where the distribution is stationary.
In~\cite{gama2004learning} authors proposed a method to detect changes in the distribution of the training examples.
The drift detection method works by monitoring the online error-rate of a model.

The next paragraph is from~\cite{gama2004learning}.
Suppose a sequence of examples $(x_i, y_i)$.
For each example the model predicts $\hat y_i$ that can be True or False.
For a set of examples the error is a random variable from Bernoulli trials.
The probability of the number of errors for $n$ examples is given by the Binomial distribution.
Probability to observe False for an example $x_i$ is $p_i$ with the standard deviation $s_i=\sqrt{p_i(1-p_i)/i}$.
Statistical decision theory guarantees that while the class distribution of the examples is stationary, the error rate of the learning algorithm ($p_i$) will decrease when $i$ increases.
A significant increase in the error rate of the model implies a change in the class distribution.

SINE1~\cite{gama2004learning} artificial dataset.
In the first concept all points below the curve $y=sin(x)$ have label 1, and all points above have label 0.
After the concept change labelling is reversed.

Machine Learning models learn the relation between input data $x$ and target variable $y$ by approximating a joint distribution $p(x,y)$. 
Model performance degrades when learned underlying data distribution changes. 
Therefore concept drift can be detected by monitoring change points in model's output performance statistics.

\section{Concept Drift examples in real and artificial data}
\subsection{Example: Insects}
% https://sites.google.com/view/uspdsrepository
% pass: DMKD2018
~\cite{SouzaChallenges2020}

\subsection{Example: Arima concept drift example}
% https://otexts.com/fpp2/AR.html
Let's consider AR(1) process.
Autoregressive-integrated moving average (ARIMA)~\cite{box2015time} model models stationary processes when the process remains in equilibrium about a constant mean level.
Forecasts are usually needed over a period known as lead time $l$.

In the autoregressive model
the current value is expressed as 
let $\tilde{y}_t = y_t - \mu$
Equation~\ref{eq:ar_proc} is autoregressive (AR) process of order $p$
\begin{equation}\label{eq:ar_proc}
  y_{t} = c + \phi_{1}y_{t-1} + \phi_{2}y_{t-2} + \dots + \phi_{p}y_{t-p} + \varepsilon_{t},
\end{equation}
where $\varepsilon_{t}$ is a white noise. 
\begin{equation}\label{eq:ma_proc}
  y_{t} = c + \varepsilon_t + \theta_{1}\varepsilon_{t-1} + \theta_{2}\varepsilon_{t-2} + \dots + \theta_{q}\varepsilon_{t-q}
\end{equation}
for stationary processes constrains are~\cite{hyndman2018forecasting} 
\begin{itemize}
  \item for AR(1) $-1 < \phi_1 < 1$
  \item for AR(2) $-1 < \phi_2 < 1, \phi_1+\phi_2 <1, \phi_2-\phi_1 < 1$
\end{itemize}
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/arima_cd_example}
	\caption{Arima concept drift example.
		Two $AR(1) $ processes.
		First and second halfs of the signal is generated by the $AR(1)$ process
	}\label{fig:arima_cd_example}
\end{figure}
% \tilde{y}_t = \phi_1 \tilde{y}_{t-1} + \phi_2 \tilde{y}_{t-2} + \dots + \phi_p \tilde{y}_{t-p} + a_t
%where $a_t \sim \mathcal{N}(\mu, \sigma_a)$.

\subsection{Example: ELEC2}
The electricity market data set ELEC2~\cite{harries1999splice, gama2004learning} is widely used for testing adaptive learning techniques.
It should be noted however that it is not clear if there is a concept drift in the dataset~\cite{zliobaite2013good}. 
%https://www.openml.org/d/151
%Electricity is a widely used dataset described by M. Harries and analyzed by J. Gama (see papers below). This data was collected from the Australian New South Wales Electricity Market. In this market, prices are not fixed and are affected by demand and supply of the market. They are set every five minutes. Electricity transfers to/from the neighboring state of Victoria were done to alleviate fluctuations.
%
The dataset (originally named ELEC2) contains 45,312 instances dated from 7 May 1996 to 5 December 1998. 
Each example of the dataset refers to a period of 30 minutes, i.e. there are 48 instances for each time period of one day. 
Each example on the dataset has 5 fields, the day of week, the time stamp, the New South Wales electricity demand, the Victoria electricity demand, the scheduled electricity transfer between states and the class label. 
The class label identifies the change of the price (UP or DOWN) in New South Wales relative to a moving average of the last 24 hours (and removes the impact of longer term price trends). 
%
%The data was normalized by A. Bifet.
%
%### Attribute information  
%* Date: date between 7 May 1996 to 5 December 1998. Here normalized between 0 and 1
%* Day: day of the week (1-7)
%* Period: time of the measurement (1-48) in half hour intervals over 24 hours. Here normalized between 0 and 1
%* NSWprice: New South Wales electricity price, normalized between 0 and 1
%* NSWdemand: New South Wales electricity demand, normalized between 0 and 1
%* VICprice: Victoria electricity price, normalized between 0 and 1
%* VICdemand: Victoria electricity demand, normalized between 0 and 1
%* transfer: scheduled electricity transfer between both states, normalized between 0 and 1
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/cd_example_elec2.pdf}
	\caption{Elec2 dataset}\label{fig:elec2}
\end{figure}

\section{Example: Sine1}
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/cd_example_sine1}
	\caption{SINE1 artificial dataset. 
		Before concept drift (CD) all points above the curve $y=\sin(x)$ are classified as positive.
After CD - as negative.	
}\label{fig:sine1}
\end{figure}

\subsection{Example: CFB signal}

Outliers in CFB cause increased calculated prediction error when predicted value is according to the linear trend. 
In continuous update model is being re-trained after using window of width $w$ $(x_{t-w}, \dots, x_{t})$.
In case of adaptive learning with change detection model is re-trained in a sliding window but if change is alarmed at moment $t^c$ then model uodates using 
If Pccf is available then 
In the CFB signal there are outliers between concept drifts.
We run a linear regression model trained using sliding window.
The model predicts $x(t)$ given $(x_{t-w}, \dots, x_{t-1})$ for $t in (1, \dots, n-1)$.
If change is alarmed due to outlier then ..

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/boiler_fixed_train}
	\caption{CFB boiler signal.
Linear regression model is trained using first 600 observations (vertical red line).	
}\label{fig:boiler_fixed_train}
\end{figure}

\section{Change detection problem}

On-line change detection in time series data is an old practical problem with the roots in the problem of statistical quality control~\cite{basseville1993detection,NISTbook}.
Walter A. Shewhart invented control charts in 1924 while working on the problem of statistical quality control to improve reliability of telephone transmission systems. 
Quality control example: $X$ is a set of sensor readings and $y=good$ is a quality of the produced item. 
Offline and online. 
In offline learning all training data is available during training. 
In online learning the data is processed sequentially from data streams.
Model is being updated as more data arrives. 
Data evolve over time in dynamically changing environments.
\begin{figure}[!htb]
	\centering
	\includegraphics[height=0.9\textwidth]{images/detectors_output_stats}
	\caption{All}\label{fig:all_detectors_stats}
\end{figure}


\section{Detectors}

\subsection{Adwin}

Adwin was proposed in~\cite{bifet2007learning}.
Confidence value $\delta \in (0,1)$
Equation\ref{eq:adwin_ecut}.
\begin{equation}\label{eq:adwin_ecut}
	\epsilon_{\text{cut}} = \sqrt{\frac{2}{m} \cdot \sigma_W^2 \cdot \ln{\frac{2}{\delta^\prime}}} + \frac{2}{3m} \ln{\frac{2}{\delta^\prime}}
\end{equation}
Algorithm\ref{alg:adwin}
\input{pseudo_code/pseudo_code_adwin}
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/example_output_adwin.eps}
	\caption{ADWIN}\label{fig:adwin_output_example}
\end{figure}

\subsection{Pelt}

Offline detector used in online settings in ~\cite{marrero2013aclac}.
~\cite{killick2012optimal}
Pelt method is based on a common approach of  minimising a cost function over possible numbers and locations of change points.
Pelt is based on~\cite{jackson2005algorithm}, but involves a pruning step reducing the computational cost but not affecting exactness of the resulting segmentation.
Dynamic programming~\cite{bellman1966dynamic}.

Time interval $I$.
Ordered sequence of data $y_{1:n}=(x_1,\dots,y_n)$.
A partition $P$ of an interval $I$ is a set of blocks is defined  by change points $\tau_{1:m}=(\tau_1, \dots, \tau_m)$.
Each change point is an integer between 1 and $n-1$.
We define $\tau_0=0$ and $\tau_{m+1}=n$.
$m$ change points split the data into $m+1$ segments, $i$-th segment is $y_{\tau_{i-1} : \tau_i}$.
For example, if there is one changepoint $\tau_1$ the segments are $B_1=y_{\tau_0:\tau_1}$ and $B_2=y_{\tau_1:\tau_2}$ where $\tau_2 \equiv n$.
The goal is to find an optimal partition by minimising the cost function defined by Equation\ref{eq:cost_function}
\begin{equation}\label{eq:cost_function}
	\sum_{i=1}^{m+1} [ C(B_i) ] + \beta f(m),\: \text{where } B_i \equiv y_{\tau_{i-1} : \tau_i}
\end{equation}
where $\beta f(m)$ is a regularization term to prevent overfitting.
Commonly used cost functions are twice the negative log likelihood~\cite{guyon1999underfitting,chen2011parametric},
quadratic loss and cumulative sums~\cite{inclan1994use, rigaill2010pruned}.
The most common choices for the regularization term are usually $\beta f(m) = \beta m$.
Examples are Akaike's Information Criterion (AIC\cite{akaike1974new}) $\beta=2p$ and Schwartz Information Criterion (BIC\cite{schwarz1978estimating}) ($\beta = p \log{n}$) where $p$ is the number of additional parameters introduced by adding a new changepoint.
Dynamic programming optimal segmentation is based on the next principle of optimality
\begin{theorem}
Let $P^{\text{max}}$ be an optimal optimal partition of $I$
\end{theorem}

\input{pseudo_code/pseudo_code_pelt}
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/example_output_pelt.eps}
	\caption{PELT}\label{fig:pelt_output_example}
\end{figure}


\subsection{Bayesian detector}

\cite{adams2007bayesian}
BD detector works by recursively estimating posterior probability distribution $P(r_t | \pmb{x}_{1:t}, \theta)$ of the \textit{run length} variable $r_t$ which is a time since the last changepoint.
Changepoint is an event when
\begin{equation}
	\operatorname*{arg\,max}_{r_t} P(r_t | \pmb{x}_{1:t}, \theta) = 0
\end{equation}
%$r_t = 0$
Every time a new measurement $x_t$ is observed the \textit{posterior} distribution is recalculated using the Bayes` theorem to update parameters of the distributions used to model data
\[
(r_t | \pmb{x}_{1:t}) = \frac{P(r_t, \pmb{x}_{1:t})}{P(\pmb{x}_{1:t})}
\]
and the law of total probability
%$P(x) = \sum_{y} P(x|y) p(y)$
\begin{equation}
	P(r_t|\:\LargeCdot) = \sum_{r_{t-1}} P(r_{t} | \: r_{t-1},\:\LargeCdot) \: P(r_{t-1}|\:\LargeCdot)
\end{equation}
to take into account values from all the runs in the past.
The \textit{prior} probability of the change $P(r_t=0|t)$ in BD detector is specified using the constant-value hazard rate $h$ which is a prior probability to observe a change and which is supposed to be known before the change detection process starts.
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/example_output_bayes.eps}
	\caption{Bayes}\label{fig:bayes_output_example}
\end{figure}


\subsection{CUSUM detector}

In this section, we describe the CuSum~\cite{Page1954} detector and its output statistic properties important for measuring performance metrics in static and dynamic settings.
Changes in the stream of measurements reflect dynamics of observed phenomenon happening in time.
Therefore, strictly speaking, any change is a gradual process.
In this paper, for simplicity, we refer to change points and to detections as individual time moments as if change would have happen instantly. If change is gradual and spans time interval then it can be reduced to a single time moment by considering the start or end of the change event~\footnote{Gradual change may become represented as an abrupt change in the time series also due to the sampling rate of measurements}.
Change points in the signal are characterized by the time moment when they happened and by the corresponding mean shift value in the signal.
\begin{definition}
	Change point is a time moment $t^c$ when statistical properties of the data stream change significantly accordingly to a predefined criteria.
\end{definition}
\begin{definition}
	Detection is a time moment $t^d$ when a detector alarms a change.
\end{definition}
For example, if $x_i \sim \mathbb{N}(\mu_1, \sigma)$ for $i < k$ and $x_i \sim \mathbb{N}(\mu_2, \sigma)$ for $i \geq k$,
then we say that a change point occurred at time moment $t_k$, i.e. $t^{\text{c}}_{k} \equiv t_k$.
In general, detection can usually be alarmed before or after a change point.
If $t^{\text{d}}_k > t^{\text{c}}_k$, then change is detected with the delay $t^{\text{d}}_k - t^{\text{c}}_k$.
%TOMMI: Can we give definition like below? I.e. to say that ALL too-early alarms are false alarms?
If $t^{\text{d}}_k < t^{\text{c}}_k$ then detection $t^{\text{d}}_k$ is a false alarm (FA).

As an input, CuSum detector receives time series of observations~\ref{eq:input_ts} usually taken at constant sampling rate.
\begin{equation}\label{eq:input_ts}
	(x_i)_{i=1}^{N} \equiv (x_1, x_2, \dots, x_N)
\end{equation}
taken at corresponding time moments $(t_i)_{i=1}^N$.
Observations and time moments are enumerated by index $i$ mapping $t_i$ to observations $x_i$ and vice versa.
CuSum works through a sequential calculation of the output statistic as follows
% Cusum rule: https://www.itl.nist.gov/div898/handbook/pmc/section3/pmc323.htm
\begin{align}
	S_0 &= 0 \nonumber \\
	S_{n} &= \max (0, S_{n-1} + x_n - \mu_0 - k )\label{eq:cusum_scheme}.
\end{align}
% Detections are alarmed at time moments when Cusum's output statistic exceeds a threshold value $h$.
Detections are alarmed at time moments when $S_{t+1} > h$, i.e. when output statistic exceeds a threshold value $h$.
In \eqref{eq:cusum_scheme}, $\mu_0$ is the estimate of the in-control state signals' mean value.
The parameter $k$ is called allowance value and it depends on the level of mean shift $\delta=\mu_2-\mu_1$ that we aim to detect.

\input{pseudo_code/pseudo_code_cusum}

\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.7\textwidth]{images/example_output_cusum.eps}
	\caption{CuSum}\label{fig:cusum_output_example}
\end{figure}


\subsection{ARL}

The key performance metric of the CuSum detector is the Average Run Length (ARL), which refers to the expected number of observations before an action is taken, i.e., before the detection is alarmed~\cite{Page1954}.
ARL refers to the FA rate before the change and to the detection delay after the change point.
When the process is in-control, the $ARL_{\delta}$ refers to a FA rate, whereas when the change has happened it refers to the detection delay.
% ARL approximation in Equation~\ref{eq:arl_approximation} is given by~\cite{siegmund2013sequential}.
However, ARL is hard to estimate analytically.
As reported in~\cite{plasse2021streaming}, one of the simplest ARL approximations is given in~\cite{siegmund2013sequential} in a form of the following equation %Equation~\ref{eq:arl_approximation}
\begin{equation}\label{eq:arl_approximation}
	\text{ARL}_{\delta} = \frac{\exp(-2(\delta-k)h') + 2(\delta - k)h' -1}{2 (\delta - k)^2}
\end{equation}
%Here, $\delta=\mu_2-\mu_1$ is the mean shift we aim to detect and
for $h' = h+1.166$.
Figure~\ref{fig:arl} depicts ARL behavior against $\delta$ (left plot) and versus threshold $h$ (right plot).
It is easy to see how ARL refers to both the FA rate and to the detection delay at the same time.
More precisely, smaller values of $\delta$ correspond to fluctuations in the signal and to the larger ARL values, whereas
larger values of $\delta$ indicate change points to be detected.
Not surprisingly, ARL decreases fast when $\delta$ is increased.
It also can be seen that by changeing $\delta$ we increase or decrease ARL value.
We will use this fact later in the experimental part when performing simulations to measure the detection delay by varying ARL values (by changing $\mu_2-\mu_1 \equiv \delta$) for static and dynamic detectors.
%
\begin{figure}[!htb]
	\centering
	\includegraphics[width=0.9\textwidth]{images/images_ecmplpkdd/arl.eps}
	\caption{
    The left plot depicts ARL as a function of $\delta = \mu_2-\mu_1$ for two fixed threshold values $h$. The right plot depicts ARL as a function of the threshold value $h$ for two fixed $\delta$ values (Equation~\ref{eq:arl_approximation}).
    Both plots demonstrate that smaller ARL values (and therefore detection delays) correspond to smaller $h$ values. It is obvious for the right plot, on the left plot this fact is depicted by the dashed line for $h=2$ being lower than the solid line for $h=4$.
    %
    Smaller $\delta$ corresponds to the fluctuations in the time series causing false alarms, larger $\delta$ correspond to changes in the level shift which are subject for detection.
    When threshold $h$ is adjusted to smaller values ARL for all $\delta$ values gets smaller (left plot), therefore detection delay is decreased but probability of FA is increased.
    %Left plot depicts that ARL values for the whole range of $\delta$ values are decreased including smaller $\delta$ values corresponding to FA events,i.e.\ average runs between false alarms are also decreased along with the detection delay.
    %
    % Our hypothesis which we investigate experimentally is that by using smaller values of $h$ within prediction intervals and by disregarding detections outside of them we can decrease detection delay and the total number of false alarms despite decreased average runs between them.
}\label{fig:arl}
\end{figure}
%\begin{figure}[!htb]
%	\centering
%	\includegraphics[width=0.7\textwidth]{images/arl3d.eps}
%	\caption{}
%\end{figure}
\begin{figure}[!htb]
\input{images/arl3d.tex}
\caption{ARL 3D}\label{fig:arl3d}
\end{figure}


