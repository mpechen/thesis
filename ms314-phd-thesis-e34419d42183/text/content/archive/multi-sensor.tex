\chapter{Multi-sensor settings}

%\\include{../relatedwork/RelMultiSensor}
\section{Related work}

Paper~\cite{Xie} refers to~\cite{mei2010efficient}

\footnote{Phrases~\cite{Xie}: ``..In the \changepoint detection literature, a surrogate for the frequency of false alarms is the average-run-length (ARL), defined to be the expected time before incorrectly announcing a change of distribution when none has occurred.''}

In~\cite{CesareAlippiMultisensor} authors address the problem of detecting changes in multivariate data streams and investigate the intrinsic difficulty that change detection methods have to face when the data-dimension scales (!!! almost copy from abstract).
Authors investigate how the data dimension $d$ of the data stream impacts on the change detectability.
It's demonstrated that change detectability progressively reduces when $d$ increases. This phenomenon is called \textit{detectability loss}.

In~\cite{SongStatChpMulti} authors propose a rigorous statistical test called \textit{density test} for detecting change of distribution in multi-dimensional data.
Given a baseline data set and a newly observed observations density test is used to decide if new observations are sampled from the underlying distribution that produced the baseline data set.
In order to compute test statistic authors employ kernel density estimator (KDE), which is a widely used non-parametric approach for learning data distribution.

The problem of detecting a change in the unlabeled multidimensional data stream is considered in~\cite{KuchevaMultiSensor}. 
The paper is about the criterion of detecting change in the distributions of the data in sliding windows $W_1$ and $W_2$.
Author proposes a computationally simple criterion for change detection, called semiparametric log-likelihood (SPLL) detector which is simpler than proposed in~\cite{SongStatChpMulti}. 
Both detectors are positioned within a log-likelihood framework.
The density approximation is replaced by a single round of k-means clustering.
% - it's about decomposition In~\cite{VespierMultiSensor}

In~\cite{MiaoMultiSensor}
Realated~\cite{Stankovic_Distrubuted_Chp},~\cite{Ohlsson_Distr_Chp}
In~\cite{AgarwalBayesMultiAnomalies}

%... Seems to be important 
In~\cite{DistributedDetectionI},~\cite{DistributedDetectionII} 

\section{Multi-sensor settings}
Bayesian approach.
Conditional independence of sensor observations means that the joint density of the observations obeys:
\begin{equation}
p(y_1, \dots, y_N | H_t) = \prod_{i=1}^N p(y_i | H_t)
\end{equation}
We need to estimate quantity $P(r_1^{(t)}, r_2^{(t)}, y_1^{(1:t)}, y_2^{(1:t)})$ where $r_1^{(t)}, r_2^{(t)}$ are current run length values and $y_1^{(1:t)}, y_2^{(1:t)}$ are observed so far data streams observations.
For change detection in the stream $y_1$ we estimate posterior
\begin{equation}
P(r_1^{(t)} \: | \: y_1^{(1:t)}, y_2^{(1:t)}, r_2^{(1:t)})
\end{equation}
Joint
\begin{equation}
P(r_1^{(t)}, y_1^{(1:t)}, y_2^{(1:t)}, r_2^{(1:t)}) = 
\sum_{r_1^{(t-1)}} P(r_1^{(t)}, r_1^{(t-1)}, y_1^{(1:t)}, y_2^{(1:t)}, r_2^{(1:t)})
\end{equation}
%\section{Bayesian change detection in multi-sensor data streams}
%\section{Mechanism for contextual information information integration}
%\subsection{On-line model update}
%\section{Computational complexity analysis}
%%%%%............. COMMENTED:
